WEBVTT

00:00.000 --> 00:02.060
you

00:30.000 --> 00:32.000
you

00:57.960 --> 00:59.960
Hey, Christoph, how's it going?

01:00.000 --> 01:24.760
Yeah, it's pretty good, you know, uh, I feel like this, yeah, it's always kind of true,

01:24.760 --> 01:26.560
but yeah, work has been pretty, pretty crazy.

01:26.720 --> 01:31.760
Been trying to get caught up on stuff and including the reading, so yeah,

01:31.760 --> 01:36.000
but I'll see if we can stick to our every Thursday schedule from now on, but yeah,

01:36.000 --> 01:37.040
we'll just have to see, I guess.

01:37.920 --> 01:38.480
Sounds great.

01:39.280 --> 01:45.120
Yeah, I didn't have much time for the reading as a consciousness conference all week, so

01:46.400 --> 01:48.320
that was very tiring.

01:49.120 --> 01:52.000
Oh, interesting, consciousness conference, that sounds cool though.

01:52.000 --> 01:56.400
So what was like any new breakthroughs or anything discussed there?

01:56.880 --> 02:01.280
Um, well, a lot of really interesting food for thought, but you know, we talked about

02:01.840 --> 02:07.200
before you and I about the free energy principle active inference and this

02:08.000 --> 02:13.920
situation that we're in, that if you can draw a mark of blanket, then you may be able to use the

02:13.920 --> 02:18.160
machinery of active inference to start making some inferences about the system's behavior,

02:18.160 --> 02:23.760
but the question is how to discover the mark of blankets, and it seems that people working on this

02:24.320 --> 02:30.400
consciousness theory called IIT, integrated information theory, that's the kind of thing

02:30.400 --> 02:39.120
that might give us tools to discover, you know, subsystems that could be considered these like

02:39.120 --> 02:45.440
blanketed modules by basically looking at how they integrate information.

02:45.440 --> 02:49.200
And it's somehow related to the entropy production within the system, but the mathematics of that

02:49.200 --> 02:54.320
was a little bit, you know, above my pay grade, especially in a 10-minute talk or a 15-minute

02:54.320 --> 02:59.200
talk, but there are some really interesting relationships, so it might be possible to

02:59.200 --> 03:02.720
analyze the system from that perspective, you just look how the information flows,

03:02.720 --> 03:07.600
and it will give you some way of basically automatically discovering what are the,

03:07.600 --> 03:13.760
you know, important subsystems of a greater system, so a lot of interesting things like that.

03:14.480 --> 03:19.920
Okay, I see, so basically given some kind of graphical model, there's some people who are

03:19.920 --> 03:27.840
working out methods to find the markup or the subsets of that model with this kind of conditional

03:27.840 --> 03:31.680
independence condition of the markup blanket, I guess.

03:32.480 --> 03:39.760
Yes, yes, so IIT has a slightly different take on it, but basically as you have some kind of

03:39.760 --> 03:46.160
graphical model, we have a transition matrix, and you can do some analysis on, you know, run

03:46.160 --> 03:51.680
a simulation of the system, and you can say like, well, they have a measure called phi,

03:52.640 --> 03:57.920
and this is the measure of the integrated information, so the important thing is how the

03:57.920 --> 04:03.520
information from the parts of the system is integrated in some of its subcomponents,

04:04.080 --> 04:11.520
and, you know, the idea there is that essentially systems that have a certain kind of degree of

04:11.520 --> 04:16.400
integrated information are more conscious than systems that do not. These information is just,

04:16.400 --> 04:21.840
you know, randomly flowing through the system. I think there are some arguments to be made that

04:21.840 --> 04:28.000
this is necessarily an incomplete view from, you know, computational perspective, like if you have

04:28.000 --> 04:34.480
computational irreducibility, then from your perspective, measuring this, you know, computing

04:34.480 --> 04:41.600
these reducible mathematical models may not capture the full dynamics of the system. It might

04:41.600 --> 04:47.760
simply look to you as if it was not integrating the information, it integrates anyway.

04:48.640 --> 04:51.280
But, as far as tools goes, it's pretty good.

04:51.280 --> 04:55.440
Yeah, I never totally got the idea of integrated information. Yeah, what is

04:56.240 --> 05:01.600
integrated information really as like an information theoretic quantity kind of?

05:03.760 --> 05:08.000
I can't really explain it myself. I just simply know that it's some kind of measure,

05:08.000 --> 05:18.560
so there's some, you know, you get the transition matrix of the system and you run the simulation

05:18.560 --> 05:23.360
and then you can compute it in some way. What it does precisely, I never looked into it because

05:23.360 --> 05:28.640
that's not my main interest. But that was one of the interesting things.

05:28.640 --> 05:34.640
There was a guy who developed a really interesting presentation where he looked at

05:36.240 --> 05:43.120
canonical neural networks. So that's a, you know, stochastic dynamical system from the

05:43.120 --> 05:49.200
perspective of integrated information theory and from the perspective of active inference.

05:49.200 --> 05:55.520
And he showed a lot of correspondences there. So that's really cool. But yeah,

05:55.520 --> 06:01.600
one thing that really struck me is that there is this, I think this duality is super important to

06:01.600 --> 06:08.240
always consider and it shows up even when I'm reading the solid state physics book and all

06:08.240 --> 06:12.800
the models and so on is that you have a system with unknown number of degrees of freedom and

06:12.800 --> 06:16.960
ultimately it's a quantum system, right? Because all systems are quantum. I don't believe in the

06:16.960 --> 06:22.640
transitions into classical. I think it's a perceptual issue, not a real issue, but decoherence

06:22.640 --> 06:30.560
somehow magically takes quantum away. So we have that. And in order to be able to construct any

06:30.560 --> 06:35.840
kind of model of that, you have to go to a weaker modeling paradigm that's full computational.

06:35.840 --> 06:40.960
You just have to simply forget some aspects of the system. There are infinitely many ways to

06:40.960 --> 06:48.320
slice that system in a way that might make sense. So we do it the way we do it because of

06:48.960 --> 06:56.400
evolutionary objectives, right? We need to keep stable temperature of our bodies so we care about

06:56.400 --> 07:03.120
temperature and things like that. So keeping this duality in mind, I think it's super important

07:03.120 --> 07:09.360
whenever discussing anything. The computational model will give you precise calculation,

07:09.360 --> 07:13.520
but you can't run it too far because of the computational cost. And any kind of

07:14.800 --> 07:20.480
reducible model will allow you to compute farther, deeper into the computation tree,

07:20.480 --> 07:24.000
but you will necessarily lose detail. And that trade-off seems to be,

07:26.400 --> 07:32.720
it's fundamental. I don't know. We will ever find a way to, it can have it too.

07:33.920 --> 07:37.600
So that was kind of cool. A lot of insights like that from various stocks.

07:38.560 --> 07:39.360
Right.

07:39.360 --> 07:41.600
These are the insights I had, not necessarily the speakers.

07:42.400 --> 07:47.280
Yeah, no, no. I definitely agree with, yeah, your kind of point about making kind of counter

07:47.280 --> 07:54.720
intuitively, making the model simpler, oversimplifying allows you to somehow get farther and understanding

07:54.720 --> 07:58.800
how something actually works. Although I was kind of curious about, so you said something about how

08:00.080 --> 08:04.080
you don't think like that, or basically how everything is quantum, right? Like all just

08:04.080 --> 08:09.360
everything eventually boils down to quantum mechanics. But like, you're kind of skeptical

08:09.360 --> 08:13.840
of the idea that we can actually just ignore quantum, or that like quantum mechanics actually

08:13.840 --> 08:19.840
doesn't apply on the macroscopic level, and that like people kind of wave it away with

08:19.840 --> 08:25.680
decoherence, but maybe, you know, everything is actually quantum after all, like even up to the

08:25.680 --> 08:30.240
macroscopic level. But I was kind of curious, like, yeah, could you expand on that a little bit,

08:30.240 --> 08:36.480
or what do you mean by that? Okay, let me give you an example from fluid mechanics, which I think

08:36.480 --> 08:41.120
I'm remembering correctly, but I lost the source, so I can't verify it. I remember reading a story

08:41.120 --> 08:46.880
about the US Navy building some super-duper fast ship, right? And they got the drawing boards,

08:46.880 --> 08:54.000
they designed it, they built it, and it turned out to be really slow. Well, they didn't account for,

08:54.000 --> 08:58.960
you know, because the equations of Navier-Stokes equations that didn't let them see is the

08:58.960 --> 09:03.600
phenomenon, which I believe is called hypercavitation, that when the propellers were spinning so fast,

09:04.480 --> 09:10.880
that it created little pockets of vacuum that was actually pushing against the boat, slowing it down.

09:10.880 --> 09:21.040
So they had to introduce some kind of weird rhythm into how the propellers were spinning to just

09:21.040 --> 09:27.920
create more chaos in the molecules of water so that these pockets of vacuum wouldn't form,

09:28.320 --> 09:33.920
something like that. So I think that's generally fundamentally how

09:37.120 --> 09:42.080
bounded computational observers have to make certain assumptions about the system

09:43.360 --> 09:49.120
that are pertinent to them in order to be able to model the things that they really care about.

09:49.680 --> 09:57.200
And my feeling is that, you know, some kind of magical phase transition from

09:57.840 --> 10:03.680
quantum nature to classical nature is simply something like that. At some level of scale,

10:03.680 --> 10:10.320
you just simply don't care about the effects of the phenomenon. But there's an interesting thing

10:10.320 --> 10:17.280
that Wolfram says, this is not exactly quantum, but it's more dark matter. He says that basically,

10:17.520 --> 10:22.320
he believes that dark matter will turn out to be the caloric of our time, as in we think about it

10:22.320 --> 10:26.880
as matter, because we are familiar with standard model of, you know, particles and interactions,

10:26.880 --> 10:30.480
which is really a model of just interactions, in my opinion, not particles, doesn't say anything

10:30.480 --> 10:34.800
about particles. But it will turn out to be the feature of the structure of space.

10:36.400 --> 10:44.000
Right? So I think this transition from quantum to classical will turn out to be something like

10:44.000 --> 10:49.440
that. And I think it's an observer, I believe that, you know, from thinking about active inference

10:49.440 --> 10:54.560
quite a lot, that it's going to turn out to be an observer, observer specific phenomenon.

10:54.560 --> 10:59.120
Because if you take the world where everything evolves deterministically, and you can simply

10:59.120 --> 11:02.800
take this assumption that you cannot model the entire universe, and you have to make these

11:02.800 --> 11:08.800
probabilistic models, then you basically recover this quantum indeterminism, because you can't

11:09.520 --> 11:13.040
say exactly what the system is going to do. So we can only have like a probabilistic

11:14.960 --> 11:20.320
probability distribution over, you know, its attractor states effectively, that you are going

11:20.320 --> 11:23.760
to observe, it's going to hit you, you know, you're going to observe this and this and this,

11:23.760 --> 11:30.800
because there are more degrees of freedom in the system than what you can observe. So the

11:30.800 --> 11:34.800
coherence is a sort of like that there's something special happening. It simply strikes me as

11:34.800 --> 11:40.880
unnecessary, you can just explain it from this perspective. And if it's unnecessary, then it's

11:40.960 --> 11:48.320
probably not there. Okay, yeah, interesting. Yeah, a lot to think about there for sure. I guess,

11:49.280 --> 11:52.400
well, I don't know, yeah, I guess the way I think about it is that,

11:55.120 --> 12:01.440
well, so just as in any system where you have kind of like emergent structures that like live,

12:01.440 --> 12:06.640
like kind of a higher level of abstraction of what's beneath them, right? Like, if you look at

12:06.720 --> 12:11.760
like what's going on on the lower level in our computers, the bunch of ones and zeroes flowing

12:11.760 --> 12:17.360
around through logic gates. But when we're actually using our computers, we think in terms of much

12:17.360 --> 12:23.600
higher level concepts like, you know, files and programs and things. And I think about it as like

12:23.600 --> 12:29.280
classical physics is the abstraction as the abstract objects that live on top of kind of

12:29.280 --> 12:34.080
the quantum, you know, hardware basically that's running at the base of things.

12:34.320 --> 12:40.640
And when we get up to the macroscopic level, those abstractions, you know, they work really well,

12:40.640 --> 12:45.280
just like when you're using your computer, the idea of a file works really well. You know,

12:45.280 --> 12:50.720
of course, something can go wrong, where you have in physics, we would call them quantum effects,

12:50.720 --> 12:54.560
quantum macroscopic quantum effects. I mean, or from the experimentalist, maybe they would see

12:54.560 --> 12:58.880
that as something going right. But to use my analogy, that would be something kind of going

12:58.880 --> 13:04.960
wrong, where actually the in the computer, if the abstraction of the higher level file system

13:04.960 --> 13:10.320
breaks down, and now we're looking at the properties of the actual hardware, because

13:10.320 --> 13:14.480
something is broken. Similarly, classical physics can, you know, can break down, we can have these

13:14.480 --> 13:20.240
macroscopic quantum effects, I guess. But I mean, that doesn't know if I'd say like that the classical

13:20.240 --> 13:26.800
reality isn't real, because you know, it seems to be the reality we deal with mostly. But I don't

13:26.800 --> 13:32.080
know, maybe it's a slight difference of perspective, I guess. But I'm not saying anything fundamentally

13:32.080 --> 13:37.840
different. Well, you're essentially saying that, you know, I wrap the lower layer into a mark of

13:37.840 --> 13:43.200
blanket and say like, well, I'm statistically independent of the features of the hardware,

13:43.200 --> 13:49.840
given this interface. And what I'm trying to say is that I think it was, I think it was

13:49.920 --> 13:54.640
Andrey Karpati, who said this on Lex Friedman, that we should be trying to look for exploits,

13:55.600 --> 14:02.720
you know, in physics. And if you so if you believe in decoherence, that it's because

14:02.720 --> 14:07.120
the impression I got from people who talk about the decoherence program, they seem to believe

14:07.120 --> 14:13.120
that there is a transition into a different regime. Right. Yeah. But but in computer science, we've

14:13.120 --> 14:18.960
learned a long time ago that all abstractions are leaky. They're only useful until, you know,

14:20.080 --> 14:27.920
suddenly, your latency of a read is high because you went went outside of the cache or whatever.

14:27.920 --> 14:33.040
So you're always by thinking this way, that you're never really in a different regime, you're just

14:33.040 --> 14:38.960
simply looking for an interface. But you're always ultimately interacting with a quantum system.

14:38.960 --> 14:44.240
This may open up possibility of people thinking about ways to, you know, jiggle the system in

14:44.240 --> 14:48.000
such a way that you will see these microscopic quantum effects. If you think that you're in a

14:48.640 --> 14:53.280
transition to a different regime, and everything is classical of this, this way up that it's not

14:54.160 --> 14:58.720
an artifact of somewhat arbitrary partitioning for the interface,

14:59.680 --> 15:03.520
then you may never really think that's possible. So that's the subtle shift.

15:04.400 --> 15:09.840
Interesting. Yeah, I know. I remember seeing that that tweak to about the exploits, which was

15:09.840 --> 15:14.240
which was kind of interesting to me. I mean, I don't know, like, to me, like, it seemed like a

15:14.240 --> 15:19.840
weird way to phrase it, because it's hard, you know, for me to imagine something like an exploit,

15:19.840 --> 15:25.280
you know, per se in physics and that, you know, like, that would almost seem to suggest it could

15:25.280 --> 15:30.720
get you to do like almost whatever you want or something. Or I don't know, I mean, you know,

15:30.720 --> 15:36.080
you could like, well, it's hard to say exactly what's meant by an exploit. But I kind of tend

15:36.080 --> 15:42.000
to think of it more as in like tradeoffs of like, you know, you're even when we exploit new laws of

15:42.000 --> 15:46.640
physics to build new things, we're always going to end up trading something of value to exploit

15:46.640 --> 15:51.520
those new laws, right? We're always going to we're going to have to pay large energy cost in one way

15:51.520 --> 15:56.720
or another. But it's just kind of opening new new opening new trade routes to trade different

15:56.720 --> 16:02.960
things is kind of how I think about it. Rather than exploits, I guess, you know, like with with

16:02.960 --> 16:08.560
all quantum technology, we haven't like gotten some crazy exploit that allows us to hack into the

16:08.560 --> 16:13.440
system and get like free, you know, energy for free or something. We've actually just opened up

16:13.440 --> 16:20.320
new possibilities of trading huge amounts of energy in time to try to, you know, you know,

16:20.320 --> 16:24.560
build new things and compute in different ways and stuff like that, maybe, but it's maybe it's

16:24.560 --> 16:29.040
kind of semantic difference, I guess. No, no, I totally, I totally agree. But this is why I'm

16:29.040 --> 16:34.160
thinking that like there, the problem with quantum is that we don't really understand what's going on.

16:34.160 --> 16:40.160
Right? Like that's the main problem. We know how to compute the mathematics. But it's there's a

16:40.160 --> 16:47.360
conceptual gap. And the more, you know, the more I think about observer theory about active inference

16:47.360 --> 16:55.520
about this necessity of constructing reducible models by bounded observers, the more I'm certain

16:55.520 --> 16:59.680
to think that like a lot of phenomena in quantum, like for instance, entanglement, you can really

16:59.680 --> 17:06.640
nicely understand it as, you know, the sort of like Bayesian, from the Bayesian modeling perspective,

17:06.640 --> 17:11.600
that you have us if systems interact, one system creates a model of another system. So it can do

17:11.600 --> 17:18.400
some it can do something, you know, like I suddenly have a particle inside a quasi particle inside of

17:18.400 --> 17:26.400
me that actually represents you. So that's how I can kind of affect your behavior in using a

17:26.400 --> 17:32.960
non local correlation, because I have this quasi particle that allows me to exploit something in

17:32.960 --> 17:38.800
you. Right. I know, for instance, you know, if we share a password or something, something like

17:38.800 --> 17:43.120
that, right, I can say that in some in some completely arbitrary context, and you may completely

17:43.120 --> 17:46.640
change your behavior, because you hear the special word where you're supposed to do something like

17:46.640 --> 17:51.200
a sleeper agent, stuff like that, you know, that will be an example of a non local correlation.

17:51.840 --> 17:56.400
Right. Yeah, yeah, definitely. Yeah. You know, interesting to think about.

17:58.560 --> 18:02.640
And in like whether, you know, whether there are any kind of quantum correlations or anything like

18:02.640 --> 18:07.680
that, you know, who knows? I mean, it's certainly been hard for us to create them experimentally,

18:07.680 --> 18:13.600
but you know, but all right, well, I guess we'll try to start to transition towards the reading,

18:13.600 --> 18:17.760
although, you know, I was hoping a few more people would come, but it's recorded. So

18:17.760 --> 18:22.480
people will be able to listen back to the space afterwards. By the way, how's it going, Laura?

18:22.480 --> 18:30.400
Thanks for coming. How did the reading go for you? Well, I kind of didn't do it, but

18:33.440 --> 18:37.920
I'm happy to be here and listen. And I was also trying to read Wikipedia because

18:38.800 --> 18:45.280
so I'm going to explain this wrong, but there's like this concept of, and apparently it's been

18:45.280 --> 18:54.720
totally debunked, but it's, it's like zero point energy where something like a particle and an

18:54.720 --> 19:02.800
antiparticle come into existence and annihilate. And oh gosh, I'm going to explain it wrong. Anyway,

19:04.560 --> 19:10.560
I'll try to find the explanation of it, but long story short, this is the type of thing that I think

19:10.640 --> 19:17.280
Carpathia was alluding to when he was talking about finding an exploit in the system. And like I

19:17.280 --> 19:24.960
said, this theory is, you know, or this idea of getting energy. And I guess the idea is something

19:24.960 --> 19:29.600
like you're actually taking energy from like a parallel universe or something when you're doing

19:29.600 --> 19:36.480
this. And, you know, if parallel universes exist, there's like, again, like none of this is even

19:36.560 --> 19:42.000
like remotely real. But, but anyway, when you're talking about, I do remember that,

19:43.120 --> 19:50.080
that moment where he was talking about exploiting loopholes and reality. And yeah,

19:50.080 --> 19:52.960
anyway, I think the energy thing is one of them. The other thing I wanted to say,

19:53.520 --> 20:01.040
when Christoph was talking about coarse grain versus fine grained explanations, I think that

20:01.600 --> 20:07.120
something that's happening now that we're just like really beginning to appreciate is that

20:07.120 --> 20:15.680
computation is expensive. And the reason why I bring it up that way is because like,

20:15.680 --> 20:21.280
I don't think that it, it like was appreciated. And I think people think like, oh, you know,

20:21.280 --> 20:26.560
we have so much because of Moore's law, we have like more access to computation, but it's just

20:26.560 --> 20:33.840
like, it's never really going to be enough. And so you have to find algorithms that, you know,

20:33.840 --> 20:38.320
do you like a good enough coarse graining of the things that don't matter? And so that way they

20:38.320 --> 20:46.160
can focus, you know, more compute on finer things that do matter and figuring out which is which is

20:46.160 --> 20:52.640
really important. You can't just like brute force everything. It's not possible. Yeah, absolutely.

20:52.720 --> 20:56.400
Actually, yeah, two things to say in response to that. First, on the point about like, you know,

20:56.400 --> 21:02.240
computation is expensive. It's yeah, it's hugely important because at least like from the

21:02.240 --> 21:06.400
background of when I was in grad school, you know, all the code I wrote was research code. It was

21:06.400 --> 21:12.320
something I'd run on my laptop to get some plots and then send to my advisor or whatever. And often

21:12.320 --> 21:16.240
those codes will be written in a very inefficient way. And, and, you know, whatever if it takes

21:16.240 --> 21:22.000
hours or days to run is what it is. But now, you know, I'm working in a setting where we write,

21:22.000 --> 21:25.760
you know, code for production. So it won't just be running on one machine and be running on many

21:25.760 --> 21:30.240
machines. Stuff that runs on the client side could potentially be running on a very large

21:30.240 --> 21:33.760
number of machines, right? And so you have to think about when you write, you know, come up with

21:33.760 --> 21:38.800
algorithms, even at the lowest level of like deriving algorithms mathematically, you have to

21:38.800 --> 21:43.440
imagine that these things are being scaled up to, you know, potentially millions and millions of

21:43.440 --> 21:47.840
people or something like that. And that's like, yeah, one of the reasons why I'm so interested

21:47.920 --> 21:51.360
in energy efficient computing, because like, even if we were just to kind of raise like,

21:52.240 --> 21:56.240
if, you know, everyone around the world was kind of living at, you know, using technology at the

21:56.240 --> 22:03.920
same standard as kind of, you know, how, how maybe, you know, we are, it would be a huge amount of

22:03.920 --> 22:09.120
energy. So it's kind of difficult to imagine, you know, how we get to like the future where

22:09.120 --> 22:13.360
everyone's able to use technology and things need to get a lot more efficient. So that's,

22:13.360 --> 22:16.720
yeah, one of the reasons I'm super interested in this like thermodynamic computing stuff.

22:18.080 --> 22:22.240
And yeah, I thought that zero point energy was a great analogy or a great example of like,

22:22.240 --> 22:27.200
what would it mean to have like an exploit of the law of physics? I think as I kind of remember

22:27.200 --> 22:32.880
what that's about is that for like a classical like mass on a spring or a harmonic oscillator,

22:32.880 --> 22:37.440
it can have an energy of exactly zero, because it's kinetic energy can be zero, it can just

22:37.440 --> 22:43.200
be sitting there motionless. Whereas for like the corresponding quantum mass on a spring,

22:43.200 --> 22:47.840
because of the uncertainty principle, it can't be, you know, the uncertainty principle says if

22:47.840 --> 22:53.280
you know where it is, then you don't know what its momentum is. And so either you don't know where

22:53.280 --> 22:57.680
it is, or you don't know how fast it's going kind of one or the other. And so either has to have

22:57.680 --> 23:02.000
some potential energy or some kinetic energy. And there's like a lowest amount of possible

23:02.000 --> 23:08.080
energy can have, which is like one half Planck's constant or something. So in the thing about

23:08.080 --> 23:12.480
it, though, that's like, it kind of misses the point of, it missed the whole point of thermodynamics,

23:12.480 --> 23:17.440
right? That like energy we can actually use is like thermodynamic free energy. It's not just

23:17.440 --> 23:22.320
energy period. So while there's, yeah, there's all this energy out there in theory,

23:23.760 --> 23:27.520
that it's not energy that can, it's not energy that's really available to you,

23:27.520 --> 23:32.640
do anything useful, I think, it's kind of the catch with the free energy stuff. But I remember,

23:32.640 --> 23:37.840
I used to play this game, it was like a famous game made by the company Valve called Half-Life 2,

23:37.920 --> 23:42.640
I don't know if any of you know it, but they had a gun in that game that you could use called the

23:42.640 --> 23:47.120
free energy gun or something, and it could like pick objects up and throw them around and stuff.

23:48.160 --> 23:52.400
It just, you know, didn't have to, you didn't have to recharge the batteries. So I imagine that's

23:52.400 --> 23:56.400
like what the kind of stuff you'd be able to do if you had the free, you know, if you could harness

23:56.400 --> 24:03.200
free energy somehow. Yeah, I thought that was a really good example actually. Okay, well, I guess

24:03.440 --> 24:07.840
we'll kind of like get started a little bit with the reading. So like the first part of this

24:09.120 --> 24:14.480
of this week's was like starting on chapter four or like page 64 on crystal lattices.

24:16.560 --> 24:21.360
So by the way, do you guys have access to like the PDF of the book?

24:26.000 --> 24:32.720
Okay, cool. Okay, well, I guess a good place to start, right, is like what is a lattice? Like what

24:32.720 --> 24:39.200
is a, yeah, they call it a Brevet lattice after this French guy Brevet, B-R-A-V-A-I-S.

24:40.640 --> 24:47.520
But the lattice is like just this very simple concept of a kind of an array of points in

24:47.520 --> 24:53.600
three dimensional space that has this property that whichever point you're looking at,

24:54.080 --> 25:00.160
it, you know, if you imagine you're sitting at some point in this array, it looks the same no

25:00.160 --> 25:06.320
matter which point you're sitting at. So for example, you could think about a simple cubic

25:06.320 --> 25:10.880
lattice. It's called a simple cubic lattice, and it's probably the most simple one to even think

25:10.880 --> 25:22.240
about. And it's just, if you just imagine you took a cube, well, okay, so yeah, you take a cube and

25:22.240 --> 25:28.160
you just pack a bunch of cubes into a box so that, you know, each cube has another cube sitting on

25:28.160 --> 25:34.320
each side of it basically. And at the point that the vertices are at the corners of those cubes,

25:34.320 --> 25:38.320
that's actually, that's the important part. Those are all points called the lattice points.

25:38.320 --> 25:43.760
And so the lattice is actually those points at the corner of the cube. And so you have just

25:43.760 --> 25:48.480
this regular array that if you take one step in either the x, y, or the z direction, you get back

25:48.480 --> 25:52.800
to another point on the lattice or another lattice point. And you can imagine that if you are sitting

25:52.800 --> 25:56.960
at one of these, if it goes, it goes forever, you know, it goes infinitely in every direction.

25:56.960 --> 26:00.960
So if you were sitting at one of these points in the lattice, you wouldn't have any way of knowing

26:00.960 --> 26:05.040
like which point you were at. None of the points looks any different from, from any others kind

26:05.040 --> 26:10.320
of. So that's kind of the definition, one definition, he actually gives two definitions,

26:10.320 --> 26:16.800
a and b. So that was a, the array of points that looks the same. And then b was, well, how do you,

26:16.800 --> 26:20.480
I like b better actually, because it's kind of constructive. It tells you how to make a lattice

26:20.480 --> 26:28.400
mathematically. And what you do is you pick three vectors in space, right? a1, a2, and a3. So each

26:28.400 --> 26:33.920
of those is a three-dimensional vector, a three-dimensional direction with, with a magnitude.

26:34.960 --> 26:40.800
And then you, you, you pick some integers, n1, n2, and n3. These are like positive integers,

26:40.800 --> 26:45.760
like one, you know, they could be one, two, three, four, whatever. And then you just multiply each

26:45.760 --> 26:50.960
of your vectors, a1, a2, or three. You take each of those and you multiply it by, by an integer,

26:50.960 --> 26:57.120
and then you add those vectors together. And that gives you kind of a point in space. And then if

26:57.120 --> 27:01.360
you try that for every, actually the n1's, the integers can go negative, they can also be zero,

27:01.360 --> 27:05.360
sorry, they, I said they are positive, but they, they aren't, they, they can be positive, negative,

27:05.360 --> 27:11.520
or zero. And so you try every possible combination of, of those integers. And remember, there's

27:11.520 --> 27:15.760
infinitely many of those combinations. And you try every possible combination, and this gives you

27:15.760 --> 27:20.400
this infinite array of points in space. So that was kind of like the definition of the lattice.

27:21.760 --> 27:25.680
Yeah, were there any thoughts about that? Like, or questions about what the lattice is,

27:25.680 --> 27:37.440
or anything like that, or Brevet lattices? Okay, so that was, I guess that was reasonably clear.

27:38.000 --> 27:41.120
But I think they give an interesting, they give a nice example of like something that

27:41.120 --> 27:48.080
isn't a Brevet lattice, which is if you can see this figure 4.3, this honeycomb,

27:49.280 --> 27:57.360
this is not a Brevet lattice. And did anybody have any kind of, yeah, anyone who want to try to

27:57.360 --> 28:13.280
take a stab at explaining why this honeycomb is not a Brevet lattice?

28:18.000 --> 28:22.080
All right, I'm going to have to call on you guys. All right, Kristoff, what do you,

28:22.080 --> 28:26.080
what do you think about this honeycomb? Does it look like a Brevet lattice?

28:28.240 --> 28:33.280
Oh, hello, Kristoff, are you there?

28:36.720 --> 28:43.680
Okay, maybe not. All right, well, Laura, I don't know, did you, can you see the figure 4.3,

28:43.680 --> 28:48.880
the honeycomb? Okay,

28:52.960 --> 29:03.120
figure 2, 4.3. Oh, no, that's figure 4. This is so confusing. Oh, I see, that's

29:03.760 --> 29:11.680
equation 4.3, figure 4.6, okay, so. I was on, sorry, I was on page 66, at least in my day.

29:12.320 --> 29:14.320
No, no, that's correct. Oh,

29:17.520 --> 29:22.560
right. Yeah, so what about this, you know, any, any thoughts like why, why it isn't a Brevet

29:22.560 --> 29:30.880
lattice, this honeycomb? So I don't know, like, the real reason, but looking at it makes me think

29:30.880 --> 29:38.080
of something that tessellates rather than forms a crystal. All right, well, okay, so yeah, so,

29:38.080 --> 29:41.440
well, I'm not sure, yeah, I honestly don't know what tessellates, yeah, what is the definition

29:41.440 --> 29:46.960
of tessellate? Tessellate, huh? Well, it's like a repeating pattern. Oh, right.

29:46.960 --> 29:53.680
It's a natural pattern that, like, all interacts with itself. I see. Well, yeah, that's, I guess

29:53.680 --> 29:58.480
that's correct in the sense that it does, right, it does look like a tessellate, it tiles the plane,

29:58.480 --> 30:03.680
so I guess that, that much is true. As far as I think like the way, like, the technical reason

30:03.680 --> 30:10.720
of, like, why this is not a Brevet lattice is that we can find, like, two points here from which

30:10.720 --> 30:15.680
it looks different. So if you go, like, if you go on your computer and you see the point P and you

30:15.680 --> 30:20.960
zoom way into the point P, so you just see these three lines, right? One line is going to the right,

30:20.960 --> 30:24.880
another one's kind of going up into the left, another one's kind of going down into the left,

30:24.880 --> 30:27.200
right? So you see those three lines coming out of the point P.

30:27.360 --> 30:35.040
And then those point to the kind of three nearest neighbors, like the three nearest lattice

30:35.040 --> 30:40.080
points, where if we went and we zoomed way in on the point R, now we have one line going to the

30:40.080 --> 30:44.560
left and one line going up into the right and another going down to the right. So in other words,

30:44.560 --> 30:49.360
if we, like, basically zoom way in and imagine you were sitting on the point P versus sitting on

30:49.360 --> 30:54.160
the point R, your surroundings would kind of look different, like, if you were on those two different

30:54.160 --> 31:01.120
points. Right, yeah, so that's how you know it's not a Brevet lattice, because in a Brevet lattice,

31:01.120 --> 31:04.560
no matter what point you're at, your surroundings would look exactly the same.

31:05.600 --> 31:11.520
Oh, okay, that makes sense. Right, so if we compare it to, let's see, they give one,

31:12.560 --> 31:19.280
an example one that is a Brevet lattice, like figure 4.1 on the previous page, here, like,

31:19.280 --> 31:23.600
if you're sitting at any of these points, your surroundings will look exactly the same in figure

31:24.160 --> 31:33.520
4.1, actually. Okay, so that was the definition. I think that basically covers, like, what is,

31:33.520 --> 31:38.240
like, the kind of the core of the idea of the Brevet lattice, because that's kind of confusingly,

31:38.240 --> 31:43.600
there's a lot of things that look, as you put it, like, tessellate the space or, like, are repetitive,

31:43.600 --> 31:50.640
but aren't lattices. And then, like, if you, of course, there can be, like, you know,

31:50.640 --> 31:55.360
materials that have a strict structure that looks more like 4.3, and if you want to describe

31:55.360 --> 32:00.080
something like that mathematically, you basically add, like, something else on top of a lattice.

32:00.080 --> 32:05.520
So there's, like, basically a lattice that includes some of the points in 4.3, and then you add

32:05.520 --> 32:10.240
something else called a basis, which basically, like, covers all the other points, and it turns

32:10.240 --> 32:16.320
out to be a useful way of thinking about it, I guess. So they talk about a few important ones.

32:16.560 --> 32:23.200
There's one called the FCC, or, well, actually, first they talk about the BCC, or body-centered,

32:23.200 --> 32:29.120
body-centered cubic lattice. And I guess that's the one where you imagine you have a cube with a

32:29.120 --> 32:33.600
point at each corner of the cube, and then there's also a point in the center of the cube. So it's,

32:33.600 --> 32:37.840
like, a little bit more complicated than the simple cubic, where you would just have points at the

32:37.840 --> 32:42.480
corners of the cube. And it's, the interesting thing about this is, like, it's not, like,

32:42.480 --> 32:46.880
at first, totally obvious, I think, that this actually is a Brevet lattice, like, because if

32:46.880 --> 32:51.120
you're at one of the corners of the cube versus being at the point in the middle of the cube,

32:51.120 --> 32:54.960
like, maybe that would look different, but it turns out that it actually is the same.

32:56.000 --> 32:59.920
So it does turn out to be a Brevet lattice where, whether you're at the corner or whether you're

32:59.920 --> 33:03.760
in the center of the cube, your surroundings are actually just going to look exactly the same.

33:04.800 --> 33:10.320
So that's, like, the BCC, and then there's also the FCC, where this is also a cube where you have

33:10.320 --> 33:14.720
added a point at each corner of the cube, but then in the center, in the middle of each, like,

33:14.720 --> 33:19.360
face of the cube, each side, you've added a point there, but you don't add a point in the middle.

33:19.360 --> 33:22.800
That one also turns out to be a Brevet lattice. And so those ones are pretty important because

33:22.800 --> 33:28.240
there's a lot of different, like, metals and materials that end up having those lattice structures,

33:28.240 --> 33:32.240
whereas the simple cubic is actually really rare. You know, you would think that would be kind of,

33:32.240 --> 33:36.960
like, the most simple, maybe that would be pretty common, but it turns out you don't really see the

33:36.960 --> 33:42.160
simple cubic lattice much in nature at all, except for some really weird, like, special cases.

33:43.680 --> 33:49.920
So, yeah, I don't know. Any other thoughts or questions on maybe, like, the FCC or BCC or anything

33:49.920 --> 34:06.080
like that? Okay, well, let's see. So I guess I'll just summarize another part, which is on, like,

34:06.160 --> 34:13.440
what is a primitive unit cell? So when you have this lattice, right, the lattice is made up by

34:13.440 --> 34:18.320
the points. It is a set of points that extends infinitely through three-dimensional space and

34:18.320 --> 34:24.160
has this repetitive structure. Now, if we want to talk about, like, kind of a portion of space

34:24.160 --> 34:30.480
within this framework, we introduced this new thing called a primitive unit cell. And what a

34:30.480 --> 34:37.040
primitive unit cell is, is it's a, first of all, it's a region of space with a finite volume,

34:37.040 --> 34:42.560
and then it has to meet kind of two conditions to be a primitive unit cell. So first of all,

34:43.600 --> 34:53.120
when you take this unit cell and you translate it through the lattice vectors, so remember those

34:53.120 --> 34:58.880
lattice, the vectors that kind of define the lattice, because the point, like, you get from

34:58.880 --> 35:05.520
one lattice point to another by adding up some combination of lattice vectors. And it's also

35:05.520 --> 35:11.360
true that for the unit cells, if I take a unit cell and I translate it by some combination of

35:11.360 --> 35:18.640
lattice vectors, then it will perfectly fall on top of another unit cell, and they'll be exactly

35:18.640 --> 35:25.360
the same, basically. And so they give a few examples in Figure 4.10 of, like, primitive unit cells.

35:26.320 --> 35:31.840
So that was, right, so I guess the two things that had to satisfy were, first of all, when you

35:31.840 --> 35:37.520
translate it through space, it, by all of the lattice vectors, it totally fills up space,

35:37.520 --> 35:43.200
and then it doesn't, it doesn't actually, like, overlap with other ones. It either falls exactly

35:43.200 --> 35:48.960
on top of them, or it doesn't coincide with them at all. And so this is just a way of, like, yeah,

35:48.960 --> 35:54.400
tiling space, basically, or kind of a tessellation, as you put it, that's, you have exactly one of

35:54.400 --> 36:01.040
these per lattice point. And so there, and there's one lattice, there's one lattice point in each

36:01.040 --> 36:07.520
unit cell, and each unit cell has one lattice point. So the interesting point about them is that

36:07.520 --> 36:11.440
they're not, like, there's not a unique way to come up with, like, the primitive unit cells. Like,

36:11.440 --> 36:15.280
there's many different ways of doing it, and that's what they kind of illustrated in Figure 4.10,

36:15.280 --> 36:22.400
is, like, all of these different ways of kind of carving up space is equally good, or at least is

36:23.280 --> 36:28.240
equally a primitive unit cell. And maybe they're not all equally good. There might be some, you

36:28.240 --> 36:32.720
know, that are, that are better than others, or more useful than others. And the one that's, I

36:32.720 --> 36:37.840
think, is kind of the coolest one, you know, it ends up being the most useful in a lot of ways,

36:37.840 --> 36:44.160
is what's called the Wigner-Seitz unit cell. And the Wigner-Seitz unit cell is actually pretty

36:44.160 --> 36:49.680
easy to find. You just, you take a lattice point, and you find all the points in space that are

36:49.680 --> 36:54.560
closer to that point than to any other, right? So if we called one point A, right, and then there's

36:54.560 --> 37:01.040
some other points near it, like B and C, if we look at any point in space, you know, we could look

37:01.040 --> 37:07.040
at its distances to A and B and C. And for some points, the closest lattice point will be A.

37:07.040 --> 37:11.440
And those points are in the Wigner-Seitz unit cell. And the interesting thing about the Wigner-Seitz

37:11.440 --> 37:16.080
unit cell is that, like, it doesn't depend on any particular coordinate system to define it. Like,

37:16.320 --> 37:21.680
its definition is this, like, totally kind of pure geometrical thing that's just based on the

37:21.680 --> 37:25.520
lattice itself. And so I kind of like that definition because it doesn't, like, actually

37:25.520 --> 37:31.120
introduce any coordinate system. And so it ends up having, like, all the same symmetries as the

37:31.120 --> 37:37.840
lattice itself are kind of inherited by this Wigner-Seitz unit cell, actually. So that was the

37:37.840 --> 37:47.440
Wigner-Seitz unit cell. Let's see. Any questions about that or comments?

37:50.720 --> 37:55.040
So that's interesting, but it depends on the, effectively, how you measure distance in space.

37:55.040 --> 37:59.280
So you have to make some assumptions about the space itself. So you're just sort of assuming

37:59.280 --> 38:06.880
you clearly on space here, right? Uh-huh. Right. Yeah, I guess that's true, right. We, yeah,

38:06.880 --> 38:14.400
we've assumed that you clearly in space. Yeah, let me think about that. Right, because when we...

38:15.920 --> 38:19.760
But I just want to make an observation that, like, this whole process of coming up with

38:19.760 --> 38:24.160
this primitive unit cells, it seems to me that, like, it's almost like trying to turn something

38:24.160 --> 38:29.200
that is, you know, this Cartesian space, the stage for action, into something that is much

38:29.200 --> 38:40.560
more like a graph. Hmm, interesting. I see. Well, yeah, I guess that's true in a way. You know what's

38:40.560 --> 38:45.600
that? What actually makes it even more like a graph is the concept that's called the coordination

38:45.600 --> 38:52.080
number. So when you look at, so again, when you look at any lattice point, it has some nearest

38:52.080 --> 38:56.960
neighbors, right? It has some other lattice points that are closer to it than any other.

38:56.960 --> 39:02.080
And some of those nearest neighbors will be the same distance away. And so you basically,

39:02.080 --> 39:07.760
you look at, like, what's the closest point to any given lattice point, and maybe that closest

39:07.760 --> 39:12.640
point is a distance of d, and then you count how many points are there that are a distance of d.

39:13.520 --> 39:18.400
And the number of neighbors it has at the distance d is then going to be called the

39:18.400 --> 39:23.680
coordination number. So that does kind of, you know, create a graph, I guess, in that each,

39:24.640 --> 39:35.840
node has its kind of nearest neighbors in a way. Interesting. Yeah. And now I guess, like, you could,

39:35.840 --> 39:43.120
there are certain changes to the metric you could do that would change this a lot, right? And it's

39:43.120 --> 39:48.080
interesting to think about what properties of the crystal don't change under some, you know,

39:48.160 --> 39:55.200
change to the metric, I guess. Like, for one thing, kind of the topology of the crystal isn't

39:55.200 --> 40:00.160
going to change, like, which things are next to which other, which lattice points are next to

40:00.160 --> 40:05.200
which other lattice points shouldn't change too much with, you know, unless you do something really

40:05.200 --> 40:13.520
crazy with the metric, I think. But yeah, I guess, like, the bigger sites in itself might change.

40:14.240 --> 40:19.920
I wonder if it would, it might still have, like, if you look at, like, figure 4.14, they have an

40:19.920 --> 40:24.960
example of a Wigner-Seitz unit cell. And I wonder if, like, if you did change the metric, it might

40:24.960 --> 40:33.360
still have kind of the same general, it might be the same kind of, what's the word, polygon,

40:33.360 --> 40:37.600
but it might just, like, be stretched in some way. But it's interesting because it's kind of

40:37.600 --> 40:42.400
important, like, not just, like, its actual proportions, but, like, how many corners it has

40:42.400 --> 40:48.640
and things like that. So some of those properties might not change too much, even a distorted space.

40:50.720 --> 40:55.520
I'm just trying to say that from, you know, the perspective of, like, how I tend to think

40:55.520 --> 41:00.080
about everything, this sounds like, this whole process of coming up with these models, it sounds

41:00.080 --> 41:06.080
like, basically, you know, you're starting with this space and we're trying to just carve it up

41:06.080 --> 41:12.080
in some way that we have these abstractions that we talked about earlier that you can move them

41:12.080 --> 41:19.760
around and they don't change, the interfaces don't change. Yeah, yeah, definitely. I mean, right,

41:19.760 --> 41:25.360
like, the core kind of simplification here, I guess, is, like, the periodicity, right, of, like,

41:25.360 --> 41:30.720
just having this, like, structure that's periodic in this, like, special way. And of course, in

41:30.720 --> 41:35.440
reality, like, the crystal, it is, like, periodic when you look at it down in the tiniest, like,

41:35.440 --> 41:39.360
microscopic level, right? But when you take, like, an actual chunk of metal in your hand,

41:39.360 --> 41:44.080
it doesn't look the same. It's like, it usually doesn't occur in that form where you see these,

41:44.080 --> 41:49.760
like, crystalline shapes, just because the actual period, the scale in which you would actually see

41:49.760 --> 41:53.840
that periodicity is, like, really, really small. And on a larger scale, you have a bunch of little

41:53.840 --> 41:58.400
crystals that are all kind of mashed together in some way. And so the large-scale thing is not

41:58.400 --> 42:03.680
really periodic. So, yeah, it definitely is. This is, like, a kind of simplification where we're

42:03.680 --> 42:09.360
saying, well, imagine that the bulk material kind of had this, the same exact, like, structure

42:09.360 --> 42:15.200
as a really tiny part of the bulk material, I guess, which, interestingly, also, like, ends up,

42:15.200 --> 42:18.160
like, giving you pretty good approximations a lot of the time, I think.

42:26.080 --> 42:29.520
So, yeah, so that was, like, the Bravais lattice and the Wigner-Seitz unit cell.

42:30.480 --> 42:34.880
Yeah, it was an interesting definition, but not, like, totally motivated at this point. I think

42:34.880 --> 42:41.200
we don't really start using it till a little bit later. But let's see. They also, they introduced

42:41.200 --> 42:45.680
something called the diamond structure, which is not a Bravais lattice. And, like, some points from

42:45.680 --> 42:50.000
sitting at some points in the lattice, the surroundings look different. Or it's not a

42:50.000 --> 42:53.120
lattice, but it's a structure. Sitting at some point in the structure, the surrounding looks

42:53.120 --> 42:56.720
different. But you could think of it as, like, and I think they say you can think of it as an

42:56.720 --> 43:04.640
FCC lattice, but where you've also added another point, like, kind of, that's translated, like,

43:04.640 --> 43:09.680
from each lattice point, you've added another point that's translated that displacement vector of,

43:09.680 --> 43:15.840
like, 1, 1, 1, like, 1 in each direction x, y, and z. So that's, like, this diamond structure,

43:15.840 --> 43:22.560
which ends up being important because a lot of materials have that structure. So I think that

43:22.720 --> 43:26.560
that's, like, basically it for this chapter, chapter four. Those are, like, all the important

43:26.560 --> 43:32.160
concepts, really. And then in chapter five, they start with something cool, which is the

43:32.160 --> 43:38.560
definition of the reciprocal lattice. So let's see. So, yeah, Kristoff, I feel like you might

43:38.560 --> 43:43.440
be familiar with this. Have you, like, you know, like, the idea of, like, vectors and co-vectors?

43:46.160 --> 43:46.880
Only vaguely.

43:47.680 --> 43:53.120
Okay, all right. Well, so this is, like, kind of the, I guess, the way they might think about this

43:53.120 --> 43:58.080
and, like, you know, differential geometry or something like that. They don't use the word

43:58.080 --> 44:05.120
co-vectors in this book. But so, right. So a vector is an element of a vector space,

44:05.120 --> 44:11.760
right, where you have these, you have these things, you have a commutative addition operation,

44:11.760 --> 44:18.800
and then you have, like, a scalar multiplication operation, and you have an identity, you have

44:18.800 --> 44:23.840
an origin. And then a co-vector is, like, an operator that acts on that space and maps.

44:24.640 --> 44:28.880
It's a function from the vector space to the real numbers. So it's input as a vector and it's

44:28.880 --> 44:35.840
output as a scalar, a real number. And given a basis, given, like, or given any set of vectors,

44:35.840 --> 44:39.680
like a set of n vectors, you can come up with something that's called a dual basis, which is

44:39.680 --> 44:45.920
a set of co-vectors. And the important thing about the dual basis is that each dual basis element,

44:45.920 --> 44:51.520
like, picks out one basis element, picks out one vector. When you apply it to one vector,

44:51.520 --> 44:56.320
it gives you an output of one. And when you apply it to any of the, any of the other vectors,

44:56.320 --> 45:01.600
its output is zero. And so it's like, this is useful when you have, like, a non-orthogonal

45:01.600 --> 45:06.160
basis, basically. When you have a more orthogonal basis, everything is easy and it is its own dual

45:06.160 --> 45:09.680
basis. But when you have a set of vectors that aren't, like, all orthogonal to each other,

45:10.400 --> 45:15.600
it's, you have to come up with a dual basis, basically, in order to, like, pick out individual

45:15.600 --> 45:22.240
basis vectors. But the defining, like, equation of the, of what's called the reciprocal lattice,

45:22.240 --> 45:29.520
which is really the same thing as a dual basis, is equation, where is it, is equation 5.4. So

45:30.160 --> 45:36.560
here, a sub j, these are what are called the primitive lattice vectors. And b sub i, those

45:36.560 --> 45:42.160
are what they're defining as the, like, the reciprocal lattice vectors. And those are the

45:42.160 --> 45:46.160
dual vectors to the, the a sub j. And you can see that, because in this equation,

45:47.040 --> 45:52.880
when you take the dot product of b sub i with a sub j, you get zero if i is not the same as j,

45:52.880 --> 45:57.040
and you get two pi if they're the same. So I guess up to that factor of two pi, it's like

45:57.040 --> 46:03.200
the exact same thing as the dual basis. Right. So it's kind of like a set of functions that

46:03.200 --> 46:11.200
allows you to effectively orthogonalize a basis. Yep. Yeah, yeah, exactly. Yeah. So yeah, these

46:11.200 --> 46:15.760
kind of things are super useful whenever you have, like, a non orthogonal basis. And because you have,

46:15.760 --> 46:22.080
like, here, like some crystal where the crystal might kind of look like a, what's the word,

46:22.800 --> 46:28.400
parallel piped when you look at the little unit cells, it's useful to basically introduce this

46:28.400 --> 46:37.680
kind of dual basis. Yeah. In the sort of broader sense, I think, in some sense, the function of

46:37.680 --> 46:46.960
neural networks is basically to do something like this for arbitrary, arbitrary basis, like there's

46:47.120 --> 46:53.200
some, you know, this sort of orthogonalization and linearization seem to be the goal of

46:53.200 --> 46:57.360
intelligent systems. Because once you do that, then you can actually start making sense out of a

46:57.360 --> 47:03.200
system. If you have bases that are not orthogonal, it becomes very difficult to think about them.

47:03.200 --> 47:08.160
And here, we're looking at this just from the linear perspective. So it's kind of like very

47:08.240 --> 47:15.280
microscopic, but neural networks kind of do it at, so to say, at scale for nonlinear,

47:17.520 --> 47:21.760
nonlinear phenomena that we're trying to model. But ultimately, they're trying to come up with

47:21.760 --> 47:26.480
representations that are as orthogonal and as linear as possible.

47:27.520 --> 47:32.320
Right. Yeah, yeah, I think that's kind of right. You can think of it almost like as an encoder,

47:32.320 --> 47:39.600
decoder kind of thing where if I have like three numbers and I want to encode them in a vector,

47:39.600 --> 47:45.600
like the simplest way is to use an orthogonal basis and come up with a vector x, y, z, where x,

47:45.600 --> 47:49.840
y, and z are the three numbers I had. But right, then I could make it more complicated where I could

47:49.840 --> 48:00.960
do x times a1 plus y times a2 plus z times a3, where now a1, a2, and a3 are three kind of weird

48:01.040 --> 48:06.960
vectors in arbitrary directions. And then you might ask, well, how can I recover x, y, and z

48:06.960 --> 48:11.200
from that vector I've constructed? And the way you do that is using the dual basis. The dual

48:11.200 --> 48:16.160
basis allows you to get out the original things you put in. So I think you can, and right, so here,

48:16.160 --> 48:19.760
because this is like the simple, like this is just linear combination. So it's really easy.

48:19.760 --> 48:23.520
And then in some like neural network architectures, you might be able to like kind of encode things

48:23.520 --> 48:28.480
in the latent space and then try to extract out, you know, something from that kind of.

48:29.120 --> 48:33.440
Exactly. You have the same kind of thing here, encoder, decoder, but here it's constructed

48:33.440 --> 48:38.880
geometrically. Yeah. Yep. Yeah, I see. Yeah, that's an interesting way to look at it. Yeah,

48:38.880 --> 48:43.040
I definitely hadn't thought about that actually. That's kind of cool. I think it's a very simple

48:43.040 --> 48:47.600
conceptual way to think about it, right? Like, because you can get lost into the, I always used

48:47.600 --> 48:53.280
to get lost in the details of what linear algebra is trying to do with the, all this vocabulary,

48:53.280 --> 48:57.600
build up around structures. When you think about all this is just essentially, you know, encoder,

48:57.600 --> 49:01.680
decoder, then it's like suddenly you're like, oh, that's, that's actually really easy to conceptualize.

49:02.480 --> 49:06.240
Yeah. Yeah, that's really good, actually. Yeah. So like, I guess you could think of like the

49:06.880 --> 49:11.680
basis and dual basis is like, it's almost like a dictionary in programming where you can store

49:11.680 --> 49:17.360
things in the dictionary. But it's a weird dictionary where the keys you use to enter

49:17.360 --> 49:21.440
things in the dictionary are different from the keys that you use to read things from the dictionary,

49:21.440 --> 49:26.080
basically. So like, for an orthogonal basis, that would be the same key. But for non orthogonal

49:26.080 --> 49:30.480
basis, you use the basis vectors to write to the dictionary, and then you use the dual basis

49:30.480 --> 49:34.720
vectors to read from the dictionary. Yeah, actually, I really like that analogy. That's a good way of

49:34.720 --> 49:42.880
thinking about it. Okay, cool. So, oh, and then another nice property of this reciprocal is that

49:43.520 --> 49:48.000
the reciprocal of the reciprocal lattice is, again, the original lattice. So it's like,

49:48.000 --> 49:53.040
something kind of, well, I forget what they call it, involution. Yeah, this is a transformation

49:53.120 --> 49:56.800
that when you do it twice, you get back to the original kind of space. So you can think of this

49:56.800 --> 50:01.760
kind of dual space as mirror image of the original, not mirror image, but like this,

50:01.760 --> 50:08.480
you know, underground image of the original space that is a different way to look at things, kind of.

50:09.680 --> 50:12.640
If you ever saw the show, like, Stranger Things, you could think of it like that.

50:15.760 --> 50:21.040
Yeah, exactly. Yeah, right now. So in solid state physics, they call it the direct lattice and

50:21.040 --> 50:25.600
the reciprocal lattice that's basically like that, the normal world in the upside down.

50:25.600 --> 50:31.040
Yeah, but you know, that's that phenomenon of like, there being these dualities, this is exactly

50:31.040 --> 50:34.560
what I was talking about earlier, that seems to be super duper fundamental that you have this,

50:34.560 --> 50:40.080
like, on one hand, you have objects, right? On the other hand, you have functions, right? There's

50:40.080 --> 50:45.360
always, there's always this duality, and there's a, there's a different kind of beast that lives

50:45.360 --> 50:49.200
in one space, and there's just the other, and there's somehow, to me, there are somehow orthogonal

50:49.200 --> 50:54.400
in some weird way, you know? Right. Yeah. Yeah, definitely. In all those, like,

50:54.400 --> 50:59.280
commutation diagrams you see in math, where it's like, you go down to like the different lower

50:59.280 --> 51:03.680
level, and then you go across, and then you go back up. And that's kind of the way, yeah, I think

51:03.680 --> 51:08.480
about these dualities, right? There are a way to get, there are a way to get from point A to point B,

51:08.480 --> 51:12.720
but instead of trying to go directly in the space you're in, you go to some other space, and then

51:12.720 --> 51:18.480
go, and then you go back to the space you were in originally, kind of. Yeah. All right, so those

51:18.480 --> 51:22.560
were the reciprocal lattices. They give a few examples, like, so those lattices I was talking

51:22.560 --> 51:26.640
about earlier, the FCC and the BCC, they're reciprocals of each other. So, like, if you have

51:26.640 --> 51:32.640
an FCC lattice, the reciprocal lattice is the BCC lattice, and then vice versa. So that's kind of

51:32.640 --> 51:40.160
a neat little factoid, I guess, about those lattices. They talk about lattice planes,

51:40.160 --> 51:46.320
Miller indices. These aren't too important, at least at the level where, you know, I mean,

51:46.320 --> 51:51.760
unless you want to get, like, super into X-ray crystallography, the Miller indices might be

51:51.760 --> 51:57.120
useful. But yeah, well, I guess the next chapter is about this X-ray crystallography stuff.

51:58.400 --> 52:03.760
And this is, like, how they're actually able to, like, kind of, like, measure the structures of

52:03.760 --> 52:07.840
crystals and, like, figure out through measurements what the structure of a crystal actually is.

52:09.440 --> 52:14.800
And it's kind of cool how it works, I guess. They talk about, like, in the book, they talk about

52:14.800 --> 52:19.600
two different, like, formulations of the X-ray crystallography, one that Bragg came up with,

52:19.600 --> 52:25.920
and the other that Fun Lalla came up with, I guess, and they first, like, start with a Bragg one.

52:25.920 --> 52:31.280
But this is, like, a pretty well-known thing in physics, this, like, Bragg diffraction. It's just

52:31.280 --> 52:36.080
the idea that when you have, like, a, you have a series, you have a bunch of mirrors that are

52:36.080 --> 52:40.240
kind of parallel to each other, but light can also kind of, like, go through the mirrors.

52:41.120 --> 52:45.680
And so when you send in light, it reflects off of, like, all of these mirrors that are parallel to

52:45.680 --> 52:53.200
each other. And then if the, when it reflects, the light can kind of destructively interfere,

52:53.200 --> 52:57.680
right, because the light is a wave. And so if the mirrors are the right distance apart,

52:57.680 --> 53:04.080
when the light reflects all the peaks of one wave will overlap with the troughs of another wave,

53:05.440 --> 53:09.760
whereas if they're another distance apart, all the peaks will kind of align with each other

53:09.760 --> 53:13.840
when it reflects. And this also depends on the angle that the light reflects at. So that's what's,

53:13.840 --> 53:19.200
what's going on. Figure 6.1 is kind of looking at, when light reflects off of these two parallel

53:19.200 --> 53:25.280
mirrors, at what angle will you have, like, destructive versus constructive interference?

53:25.920 --> 53:31.200
And that's, like, really the key to investigating the structure of a crystal, is to know, like,

53:31.200 --> 53:35.200
how that Bragg diffraction works, because then you can kind of send in light at a bunch of different

53:35.200 --> 53:40.240
angles, and you'll see at some angles you get, you see a reflection, and at other angles you

53:40.240 --> 53:46.000
don't see any reflection, because there's that destructive interference. So that's the basic

53:46.000 --> 53:57.040
idea of that, like, Bragg diffraction thing. Let's see. And then there's, there's another,

53:57.040 --> 54:02.320
like, formulation of it, which is, like, the Von Lauer formulation, but they're equivalent,

54:02.400 --> 54:07.280
like, the Bragg diffraction and the Von Lauer diffraction are, like, just equivalent ways of

54:07.280 --> 54:11.840
looking at the same thing. So, like, for Bragg diffraction, this key, the key equation is equation

54:11.840 --> 54:18.960
6.2, n lambda, where lambda is the wavelength, and n is, like, any integer. So any integer

54:18.960 --> 54:24.160
number times the wavelength is equal to 2d times the sine of theta, and d is the distance between

54:24.160 --> 54:29.840
parallel lattice planes, and theta is the angle that the reflection is at. So that's, like, the key,

54:29.840 --> 54:33.440
like, this equation, when this equation is true, you'll see a reflection, when it's not,

54:33.440 --> 54:38.080
you don't really see one. And then there's, like, another way of looking at it, which is the Von Lauer

54:38.080 --> 54:43.120
kind of picture, which I guess is summarized by which equation here. I think it's, like,

54:44.560 --> 54:52.080
equation 6.5 that is kind of formative in terms of the k vector of the light that's reflected,

54:52.080 --> 54:57.520
transmitting that incident and leaving the surface, where k is, like, coming in and k prime is going

54:57.520 --> 55:02.640
out, and it's looking at the difference between those. And the k vector is, like, basically the

55:02.640 --> 55:06.320
momentum of the light, and so this is the condition, this is just another way of looking at the

55:06.320 --> 55:12.880
condition that you'll actually see, you'll see a reflection or not, basically. So yeah,

55:12.880 --> 55:17.760
any thoughts or kind of questions on the crystallography stuff?

55:21.840 --> 55:22.400
None for me.

55:23.120 --> 55:28.320
Okay. Yeah, yeah, I didn't find this part, like, super interesting, you know, honestly, I mean,

55:28.320 --> 55:34.400
it's useful experimentally, but it doesn't tell you much about, like, the actual behavior of the

55:34.400 --> 55:40.320
material, so it's just kind of, it's more a kind of historical thing of how they actually figured

55:40.320 --> 55:44.720
all this out, like, how they figure out that the crystal looked like this at a microscopic level, I

55:44.720 --> 55:51.360
guess. Now, chapter 7 is, like, probably the most, maybe the most, like, pure math in the book,

55:51.440 --> 55:55.600
because it's, like, kind of talking about group theory, and, like, groups of

55:56.720 --> 56:02.960
symmetries that a lattice has. So, of course, like, that lattice can be translated by a lattice

56:02.960 --> 56:06.880
vector, and that's a symmetry. That was actually the definition of the lattice, was that, like,

56:06.880 --> 56:10.880
well, essentially the definition was that you translate it by all these lattice vectors,

56:10.880 --> 56:14.160
and you get back the same thing. But there's other symmetries you can do, like,

56:14.160 --> 56:17.840
you can, sometimes you can rotate the lattice, and you get back the same thing as well.

56:18.800 --> 56:22.320
And so, it turns out, like, well, you have, like, an infinite number of

56:22.320 --> 56:27.280
lattices you can have. There's only a finite number of symmetry groups that the lattice can have,

56:27.280 --> 56:31.600
and so that's, like, how they actually classify them, is by what the symmetry group of the lattice is.

56:32.560 --> 56:36.880
And it's kind of cool that there's, there's seven of what they call point groups,

56:36.880 --> 56:42.720
which are, the point group is, like, the set of rotations you can do to a lattice that leaves it

56:42.800 --> 56:48.720
the same. And the, and then there's 14 of what they call space groups. And a space group is when

56:48.720 --> 56:54.080
you're allowed to do a rotation and a translation. And so they're, and so those are basically,

56:54.720 --> 56:57.360
you can think of it as, like, the important thing are the space groups, like, these are

56:57.360 --> 57:03.200
all of the symmetries the lattice can have. And then those can be grouped into point groups.

57:03.200 --> 57:08.800
So, some space groups are members of the same point group. And so, for example, they talk about,

57:08.800 --> 57:15.360
like, the cubic, the point group of the cubic lattice and the point group of, like, tetragonal

57:15.360 --> 57:20.240
lattices. And then they break down, like, what are the space groups, like, within those. But,

57:20.240 --> 57:25.040
yeah, so that's just kind of a point on, like, how you classify them, which may be interesting

57:25.040 --> 57:31.600
from, like, a mathematical perspective, I don't know. That is way over my head in terms of maths.

57:32.800 --> 57:36.720
Yeah. Yeah, honestly, yeah, mine too. I haven't done too much. I mean, a little bit of group here,

57:36.720 --> 57:42.400
but it's, yeah, actually, like, figuring out, like, how do they figure out that there are only 14

57:42.400 --> 57:53.040
is, yeah, I wouldn't know how to do that, honestly. But so, you know, the main gist of what I'm getting

57:53.040 --> 57:58.720
out of these couple of chapters is basically, so we have space. There is this assumption that

57:58.720 --> 58:03.600
all kinds of things can happen to space. So we figure out a way of partitioning it in such a way

58:03.600 --> 58:09.760
that we define some interfaces between little regions of it. And then it turns out that by

58:09.760 --> 58:14.400
adding these constraints about how we are going to put partition space with, in such a way that

58:14.400 --> 58:20.640
the interfaces hold, there is only a finite way in which these things compose in such a way that

58:20.640 --> 58:26.240
the structure is preserved. So suddenly you have something that had basically infinite degrees of

58:26.240 --> 58:32.480
freedom, Cartesian empty space, where, you know, things can just float around willy-nilly. And

58:32.480 --> 58:39.040
suddenly you have something that actually has still a lot of degrees of freedom, but it's a

58:40.400 --> 58:44.720
more defined structure that you can start investigating properties of, like this periodicity

58:44.720 --> 58:51.520
and so on and so forth. Yeah, yeah, definitely. And I think what jumps out to me is that the

58:51.520 --> 58:56.480
definition of the lattice was, like, super simple. Like, it's just pick three vectors in space and

58:56.480 --> 59:01.840
then do every single translation you could think of using those, using any combination of those

59:01.840 --> 59:07.280
three vectors. And it seems like, you know, no matter what three vectors you pick, you get something

59:07.280 --> 59:12.480
that's kind of similar, right? Like, it feels like, you know, you can kind of twist the thing a little

59:12.480 --> 59:17.360
bit or kind of shear it in different directions or extract it in different directions. But it feels

59:17.360 --> 59:22.160
like, well, we're just kind of generating an array of points in three dimensions. And so the thing

59:22.160 --> 59:27.360
that to me is kind of surprising is that out of the map, there pops out, well, actually, not all

59:28.160 --> 59:32.400
there are kind of different categories of lattices that in this way of generating them,

59:32.400 --> 59:37.600
you can end up with. And there turned out to be these exactly 14 special categories of them,

59:37.600 --> 59:41.120
which to me was like pretty surprising and interesting that like, even though it feels

59:41.120 --> 59:46.560
like this kind of homogeneous and simple way of generating things through linear combinations,

59:46.560 --> 59:52.000
you end up with these 14 kind of families, I guess. But yeah. Yeah, right. That's quite

59:52.000 --> 59:56.080
surprising because it feels like almost as if you had like this continuous space of

59:59.120 --> 01:00:03.680
deformations from one lattice to another, like if I jiggle the vectors just a little bit,

01:00:03.680 --> 01:00:08.800
why would I fall into one category versus another? They're almost identical quote unquote.

01:00:08.800 --> 01:00:13.920
Yeah, no, exactly, exactly. I think the key to it is that you can lose the symmetry basically,

01:00:13.920 --> 01:00:18.640
right? Like you can start out with three vectors, like you can start out with the orthogonal basis

01:00:18.720 --> 01:00:23.360
of just the x, y, and z unit vectors. And that's like perfectly symmetrical. And so there's a

01:00:23.360 --> 01:00:27.760
bunch of symmetry operations you can do that map it back onto itself. But then if you just make

01:00:27.760 --> 01:00:32.960
one of those vectors a tiny bit shorter, now you've lost that symmetry because some operations won't,

01:00:32.960 --> 01:00:36.240
you know, preserve the symmetry anymore. And so I think that's basically where it kind of comes

01:00:36.240 --> 01:00:40.320
from is that you have this hierarchy of different symmetries and doing different deformations,

01:00:40.320 --> 01:00:46.480
you lose some symmetry basically. That's a good insight. Yeah. Thanks for highlighting that.

01:00:46.800 --> 01:00:52.160
That's really, really interesting. Yeah. So it's kind of cool. And it's neat,

01:00:52.160 --> 01:00:56.160
just I guess, because like just because the way that the solids like form on this microscopic

01:00:56.160 --> 01:00:59.920
level, they'll tend to like to form into a certain symmetry, and they'll be really,

01:00:59.920 --> 01:01:05.040
really symmetrical at that bottom level. But then sometimes with the right combination of atoms,

01:01:05.040 --> 01:01:08.560
they like to form in a way where you're missing some important, you're missing some symmetry or

01:01:08.560 --> 01:01:12.160
something like that. So yeah, it's kind of neat about this classification thing, I guess.

01:01:13.040 --> 01:01:18.640
Isn't necessarily like the art of creating some, you know, I don't know if it's the right term,

01:01:18.640 --> 01:01:24.800
but like composite materials is basically add a little bit of some other material,

01:01:24.800 --> 01:01:28.720
and that would be essentially breaking, potentially breaking some symmetry so that you

01:01:28.720 --> 01:01:34.160
get interesting properties out of that. Yeah, yeah, yeah, exactly. Right. So yeah, when you add some,

01:01:34.880 --> 01:01:38.640
yeah, when you, and then that's like when they make like semiconductors and stuff, I think they

01:01:38.640 --> 01:01:43.360
they basically like dope semiconductor devices, they'll dope, you know, silken with some other

01:01:44.320 --> 01:01:48.080
atom, basically add a little bit of impurities. And then, and yeah, you probably, well,

01:01:48.800 --> 01:01:54.400
I think like with the impurities, though, that's not like those are probably things that just like

01:01:54.400 --> 01:01:59.600
end up like here and there, but like are not like all over the lattice space, like in other words,

01:01:59.600 --> 01:02:04.640
there wouldn't be with one of those impurities in every single primitive unit cell. So that kind

01:02:04.720 --> 01:02:08.000
of makes it like, you know, a little bit less ordered, because you have all these little,

01:02:08.720 --> 01:02:13.280
you know, defects, I guess, or little impurities in various places, whereas like it's more kind

01:02:13.280 --> 01:02:18.080
of at the molecular level, if I choose the right molecule to like build my lattice out of that

01:02:18.080 --> 01:02:23.760
molecule might like to build structures with a certain symmetry or might like structures of,

01:02:23.760 --> 01:02:29.760
you know, less symmetry or something like that. Yeah, if you have time at the end of the space,

01:02:29.760 --> 01:02:33.920
remind me to tell you about one thing from this consciousness conference about

01:02:35.520 --> 01:02:41.280
electrical versus electrochemical neurons. For sure. Yeah. Well, actually, yeah, we could,

01:02:41.280 --> 01:02:45.120
we could do kind of an interview, I guess, to talk about that, because that sounds pretty

01:02:45.120 --> 01:02:49.760
interesting. So, yeah, do you want to just do that now? Okay, so one of the speakers, there was

01:02:49.760 --> 01:02:56.480
this panel about, you know, functionalism, whether it's a valid approach. So this is the idea that

01:02:56.480 --> 01:03:00.960
like, you know, if you have a causal structure that implements a given function, then it is the

01:03:00.960 --> 01:03:05.200
same as another causal structure that implements an event function. So if you take the functionalist

01:03:05.200 --> 01:03:08.400
approach to consciousness, then something like substrate independence becomes possible.

01:03:09.040 --> 01:03:13.520
Consciousness of machines becomes possible simply so like if it, if it walks like a duck,

01:03:13.520 --> 01:03:18.080
walks like a duck, looks like a duck, if it's functionally equivalent to a duck, it is a duck.

01:03:18.720 --> 01:03:25.920
And one of the panelists was in a symposium, he was, he was arguing about the sort of

01:03:25.920 --> 01:03:31.600
privileged nature of meat and biology. And he was doing that by making an argument.

01:03:34.800 --> 01:03:39.760
It was kind of interesting, he was, he made this argument that about the similarity of

01:03:40.800 --> 01:03:46.560
electrical and electrochemical neurons, that there was a paper, I think, from the 1940s,

01:03:46.560 --> 01:03:52.240
that showed that you can, if you have a purely electrical, electrical neuron, you can still

01:03:52.320 --> 01:03:59.600
do inhibition with that, that you don't need the electrochemical neurons to, to have this like

01:03:59.600 --> 01:04:03.920
gap to, to do inhibition through, you know, the chemical processes.

01:04:03.920 --> 01:04:05.840
Sorry, what does that mean, inhibition?

01:04:07.360 --> 01:04:13.200
So, you know, in a, in a, in a digital neural network, you have like that, you can have positive

01:04:13.200 --> 01:04:19.280
and negative weights, right? So when neurons fire, the chemicals released into the environment

01:04:19.280 --> 01:04:23.120
inhibit other neurons from firing, they prevent them from, from firing at the same time.

01:04:23.760 --> 01:04:28.640
So there, there is like a second layer of propagation of the signals, so to speak,

01:04:29.440 --> 01:04:35.360
that alters the environment of other neurons, and then they may not fire in case of some,

01:04:35.360 --> 01:04:40.400
some of their neighbors firing, even though the electrical potentials around them are high enough

01:04:40.400 --> 01:04:47.440
for them to be activated. So what I found interesting about this is that I think it made me think that

01:04:47.440 --> 01:04:52.240
he, so, so he was saying that there might be something special about bi, living biological

01:04:52.240 --> 01:04:57.200
systems because these two kinds of neurons are equivalent. But that struck me as a sort of,

01:04:57.200 --> 01:05:01.600
that you can do inhibition with electrical neurons. That struck me as a kind of an interesting,

01:05:03.200 --> 01:05:09.680
interesting, wrong conclusion from, from, from the data, that whether, even if you can do inhibition

01:05:09.680 --> 01:05:16.240
with electrical neurons alone, the electrochemical structure probably removes more degrees of

01:05:16.240 --> 01:05:22.480
freedom. So it's kind of like, you know, creating something a bit like those, those symmetric

01:05:22.480 --> 01:05:27.520
groups or something like that, that even, even if, in principle, if you can do it with electrical

01:05:27.520 --> 01:05:35.680
neurons alone, there is probably going to be some kind of nth order interference from just being

01:05:35.680 --> 01:05:41.680
immersed in the same electric field that, you know, it's gonna, it's good, you're never gonna

01:05:41.680 --> 01:05:45.760
be able to get rid of, that you're always receiving noise from, from everything else.

01:05:45.760 --> 01:05:54.240
But if you add electrochemical junction, and you can find this, you know, electrical firing

01:05:54.240 --> 01:06:01.680
process that way, then you're sort of breaking that, breaking that symmetry. You're adding more

01:06:01.680 --> 01:06:08.880
structure that is, that is giving you insulation from what's happening, you know, in other

01:06:08.880 --> 01:06:13.520
electrical signals around you. So it's struck me as something kind of, kind of interesting and

01:06:13.520 --> 01:06:19.680
important. So like that might be, that might be basically the function of the reason why you

01:06:19.680 --> 01:06:24.800
have it is precisely because you want to, it's kind of like adding those, adding those impurities

01:06:24.800 --> 01:06:32.080
to the material, right? You want to prevent chatter from one part of the material, the dependence of

01:06:32.080 --> 01:06:38.160
one part of the material to another, just by adding something that will, that will keep the

01:06:38.160 --> 01:06:43.920
signal localized. I see. So it's kind of what you're saying, the idea is that kind of like,

01:06:43.920 --> 01:06:49.520
while you can do inhibition with just electrical neurons, and honestly, I don't really know what

01:06:49.520 --> 01:06:53.920
electrical neurons are, but while you might be able to do inhibition with electrical neurons,

01:06:53.920 --> 01:06:58.320
that might also kind of create some side effects, because like you don't have enough degrees of

01:06:58.320 --> 01:07:04.400
freedom to like specify the behavior you want without creating additional, you know, changes

01:07:04.400 --> 01:07:10.960
or something. Yeah, exactly. Think about it as a MLP versus CNN in digital neural networks, right?

01:07:12.000 --> 01:07:16.560
A multilayer perceptron is a universal function approximator. And yet it's really difficult

01:07:16.560 --> 01:07:23.120
to train it to do the, on a classification task compared to a convolutional neural network. And

01:07:23.120 --> 01:07:30.160
convolutional neural network effectively removes the dependence of, you know, some output neurons

01:07:30.160 --> 01:07:35.920
and some of the input neurons. You're just kind of like, trim it by adding this requirement for

01:07:35.920 --> 01:07:40.560
translation equivalence, but you're effectively constraining a receptive field, layer to layer.

01:07:41.520 --> 01:07:47.120
So it's something similar that you need this, you add these constraints. So it's like you

01:07:47.120 --> 01:07:53.680
remove degrees of freedom effectively, right? But that allows you to express deeper in some

01:07:53.680 --> 01:07:59.200
sense a richer, richer set of computations, because you don't have kind of like this,

01:08:00.080 --> 01:08:05.040
a quote unquote, destructive or constructive interference from, from neighboring neurons.

01:08:06.480 --> 01:08:10.880
Oh, right. I see. Yeah, right. I see. And that, yeah, when you have kind of,

01:08:10.880 --> 01:08:17.360
in the convolutional neural network has more symmetry, and also like fewer kind of connections

01:08:17.360 --> 01:08:25.760
per activation, I guess. So it has kind of less complexity compared to a MLP that has the same

01:08:25.760 --> 01:08:30.640
number of activations, basically. I see. So yeah, there's this kind of relationship between,

01:08:30.640 --> 01:08:34.800
yeah, symmetry and complexity. I see. That's, that's pretty interesting. It seems to run,

01:08:34.800 --> 01:08:42.000
it seems to run pretty deep. Right. That you, you remove some symmetries and you can get,

01:08:42.080 --> 01:08:46.080
you can get some really interesting, interesting complexity as a result.

01:08:46.640 --> 01:08:52.880
Right. Remove or add. Sorry, I'm not, I'm not super well versed with this lingo. I guess remove.

01:08:54.000 --> 01:08:58.800
Yeah. Yeah. And I guess like, yeah, to try to like, yeah, kind of make an analogy with the

01:08:58.800 --> 01:09:05.680
crystals in some sense, like, like changing a crystal structure from like, cubic to kind of a

01:09:05.680 --> 01:09:11.440
rectangular prism, and that like removes the symmetry. It kind of, well, it adds complexity in

01:09:11.440 --> 01:09:15.520
a way, but it's different from like adding a bunch of other molecules. Like it just kind of,

01:09:15.520 --> 01:09:19.600
yeah, reduces the symmetry of it. That might be kind of like taking a convolutional neural network

01:09:19.600 --> 01:09:25.760
and saying, instead of having kernels that are like square, I'm going to have kernels that are

01:09:25.760 --> 01:09:30.000
rectangular or something like that. You know, I wonder, you know, that would, I guess, change

01:09:30.000 --> 01:09:34.800
kind of the equivalence properties of it in some way. Yeah. And there are, there is some work that

01:09:34.800 --> 01:09:41.600
makes them, I think hexagonal and it has to do, there are some extensions like that, but they're

01:09:41.600 --> 01:09:48.160
beyond, they'll be on my pay grade. But yeah, they do lead to interesting properties. Right.

01:09:50.000 --> 01:09:55.280
Right. Yeah. And I guess like, yeah, you're never going to have like total, you have like kind of

01:09:55.280 --> 01:10:00.560
symmetries by a 90 degree rotation, right? Because everything is pixels, but you don't have

01:10:00.560 --> 01:10:05.280
symmetry by like kind of a, like other arbitrary rotations, which is kind of interesting. So

01:10:05.280 --> 01:10:09.040
maybe with the hexagonal, you get a little bit like different rotational symmetries or something.

01:10:09.600 --> 01:10:15.280
So, you know, the reason why I keep bringing this up is that I can't, I can't help, but I'm

01:10:15.280 --> 01:10:19.920
starting to see this, this tradeoff everywhere. And I think that understanding this tradeoff

01:10:19.920 --> 01:10:25.600
will yield some really interesting novel insight. Right. Yeah. Well, and what's really interesting

01:10:25.600 --> 01:10:31.360
to me too is that like symmetries are also like fundamentally important in, in thermodynamics,

01:10:31.360 --> 01:10:38.400
because when you like apply, well, when phase transitions happen, you often have like a spontaneous

01:10:38.400 --> 01:10:42.960
like symmetry breaking, like where you like, let's say you have a cube, but it could be kind of

01:10:42.960 --> 01:10:48.160
stretched into a parallel pipe bed, but it could stretch in like different directions or something

01:10:48.160 --> 01:10:53.200
like that. Right. And so maybe like when, maybe when you lower the energy, in other words, like

01:10:53.200 --> 01:10:57.440
lower the temperature, maybe it wants to, to stretch into a lower, you know, into a parallel

01:10:57.440 --> 01:11:02.080
pipe bed, but has to kind of choose which way to go. And that's, and it's going to lose symmetry

01:11:02.080 --> 01:11:08.160
as a result of that. And it's kind of hard to do that. Like it's kind of hard to lose symmetry

01:11:08.160 --> 01:11:12.880
when you, when you have symmetry. And so that's like where kind of, I guess some of the energy,

01:11:12.880 --> 01:11:16.160
you know, goes in, in these like phase transitions, which is kind of interesting, but

01:11:17.120 --> 01:11:23.920
Yeah. Right. Yeah. So, so in there, it's kind of cool, because you can like these, these like,

01:11:23.920 --> 01:11:28.800
like we were talking about how you have these like 14 separate families of symmetries. It's,

01:11:28.800 --> 01:11:33.120
and that's just kind of an abstract mathematical thing. But then in physics, you can actually see

01:11:33.120 --> 01:11:38.240
like the discrete, you know, kind of like discontinuous transition from one symmetry group

01:11:38.240 --> 01:11:42.560
to another when you cross phase transitions. So they, they end up being like physical kind of

01:11:42.640 --> 01:11:47.760
phenomena. It's kind of cool. Yeah. That's really cool. Yeah.

01:11:50.480 --> 01:11:54.640
Okay. Yeah. So that, yeah, that was, that was definitely, oh, actually, that there's one

01:11:54.640 --> 01:11:57.760
of the question I wanted to ask about that. So yeah, so connecting it back to the thing you

01:11:57.760 --> 01:12:02.800
were talking about, like the functional view of things, like David walks like a duck or whatever

01:12:02.800 --> 01:12:11.360
it is a duck. So yeah, what's the relationship there, I guess? Well, these people have been

01:12:11.360 --> 01:12:18.880
trying to make, in my opinion, in the very unsuccessfully, the argument that the functionalist

01:12:18.880 --> 01:12:22.640
approach to understanding consciousness is bound to fail because there is something privileged

01:12:22.640 --> 01:12:27.120
about the substrate that, you know, the fact that you're running on wet where matters.

01:12:28.240 --> 01:12:32.320
And there's another dimension here, you know, people, people talk about this notion of mortal

01:12:32.320 --> 01:12:37.520
versus immortal computation, the mortal computation is, you know, dies when the hardware dies and

01:12:37.520 --> 01:12:42.480
the immortal computation lives on. That's the kind of Turing Turing computation on this abstract

01:12:42.480 --> 01:12:48.880
machine. Okay. To me, you're basically saying that like, well, this argument in context of

01:12:48.880 --> 01:12:53.040
consciousness is essentially saying that like, well, we believe in the quantum nature of consciousness

01:12:54.160 --> 01:12:59.440
without using the word quantum, right? That effectively, a quantum state is the only thing

01:12:59.440 --> 01:13:05.920
that we know of that cannot be copied. So if your consciousness is dependent on entirety of the

01:13:05.920 --> 01:13:11.680
quantum state, if it's somehow generated by it, then obviously, you know, you can't extract it from

01:13:11.680 --> 01:13:18.080
you and upload yourself into a computer. If on the other hand, you can distill, you know,

01:13:19.120 --> 01:13:25.680
the causal structure that makes you you into an abstract form that's suitable to run on top of

01:13:27.680 --> 01:13:34.160
a Turing machine, then so you have this immortal computation, then there is a possibility of

01:13:35.120 --> 01:13:41.520
achieving substrate independence. And I think the mistake they make is that

01:13:42.240 --> 01:13:49.840
a lot of these people, you know, somehow are married to the idea of what makes them them,

01:13:49.840 --> 01:13:54.000
that I'm the kind of person who is blah, you know, I'm the kind of person who has a body and so on

01:13:54.000 --> 01:13:59.840
so forth. Obviously, if my consciousness moves to a digital computer, I don't expect to have the

01:13:59.920 --> 01:14:06.880
same experience that they have in my meat sack, right? So I'm not the meat sack. It's just how I

01:14:06.880 --> 01:14:11.440
experience it. So I don't need to take all this detail with me to be me. I'm not my memories.

01:14:11.440 --> 01:14:17.920
I'm not my thoughts. I'm not my ideas. I'm something else. I'm the watcher of all of this.

01:14:17.920 --> 01:14:23.520
That is what really consciousness is, not any content of it. So they're basically without

01:14:23.520 --> 01:14:29.600
saying so. In my opinion, this is either smuggling God or quantum theory into the

01:14:29.600 --> 01:14:35.520
conversation about consciousness. Okay. Yeah. So one kind of point I wanted to make is that

01:14:35.520 --> 01:14:40.640
to me, like the idea of this like functionalism that like, well, yeah, what is the thing,

01:14:40.640 --> 01:14:46.240
you know, it just is defined by its kind of inputs and outputs, how it behaves. To me,

01:14:46.240 --> 01:14:52.240
like this is kind of a, in time, this is like a backwards looking rather than forwards looking

01:14:52.320 --> 01:14:58.960
approach. Because I think that like very frequently often, we've had kind of a collection of things

01:14:58.960 --> 01:15:05.360
that appear to behave the same in every way. Like, for example, to connect to the book,

01:15:05.360 --> 01:15:10.720
maybe we have different metals that have very similar conductivity. And so from people in,

01:15:10.720 --> 01:15:15.520
you know, the 19th century, they would say, well, that functionally, they're the same. So these are

01:15:15.520 --> 01:15:20.640
the same thing or something. But then later on in time, we figure out a new measurement to take.

01:15:21.280 --> 01:15:26.240
And we see that they can be distinguished from each other. So I think like the functionalism,

01:15:26.240 --> 01:15:32.480
it assumes like that you won't get new information later that does allow you to distinguish the

01:15:32.480 --> 01:15:37.280
things, I guess. And so you kind of prematurely decide that these are the same because they

01:15:37.280 --> 01:15:41.360
both walk like a duck, but I don't know how to actually distinguish them yet. So that's like,

01:15:41.360 --> 01:15:44.320
yeah, that was one kind of point I wanted to make that the functionalism is kind of like

01:15:44.320 --> 01:15:50.000
backwards looking. Not that that's wrong, but I just think that's like, because sometimes people

01:15:50.000 --> 01:15:54.960
use like backwards looking as like a pejorative, but I just kind of literally, I think it's kind of

01:15:54.960 --> 01:16:01.360
backwards looking in that. No, I understand. I think it's a very good point. Yeah. And then

01:16:02.880 --> 01:16:07.760
I actually forgot everything I was going to say. I think it was related to what you're saying after

01:16:07.760 --> 01:16:14.080
that. But yeah, I kind of forgot. It totally resonates that like, you know, basically what

01:16:14.080 --> 01:16:18.320
you're saying is that we talked about this computational irreducibility. What you're really

01:16:18.320 --> 01:16:25.760
saying is that if you take functionalist approach, you necessarily by virtue of only being able to

01:16:25.760 --> 01:16:34.400
measure certain things, you extract a computationally reducible representation of the system. And that

01:16:34.400 --> 01:16:41.520
system could have done some amazing things later down the line because of the irreducible properties

01:16:41.520 --> 01:16:46.720
that you were not able to carry, right? And this goes back straight to quantum. You cannot copy the

01:16:46.800 --> 01:16:51.440
quantum state. Right, right. Oh, yeah, that reminds me. Okay, I remember the other thing I was going

01:16:51.440 --> 01:16:57.760
to say, which was that the question of like whether, you know, so you're saying like, well, if quantum

01:16:57.760 --> 01:17:02.560
is if quantum phenomena are really important to like who we are fundamentally, right, like not the

01:17:02.560 --> 01:17:07.760
things I've experienced, but who experienced them, then you won't be able to, you know, take into

01:17:07.760 --> 01:17:12.400
measure a person's quantum state and upload it to the computer. And I think that that that makes

01:17:12.400 --> 01:17:19.120
sense. And I also I think that like the question of like whether quantum phenomena are important to

01:17:19.120 --> 01:17:25.920
like consciousness, or at least to thought, I guess, which is which is different. But I think

01:17:25.920 --> 01:17:29.760
that that question probably can be answered within like the next like 50 years, that would kind of

01:17:29.760 --> 01:17:36.000
be my my wild guess. Because I think that that's something that like, we basically know how we

01:17:36.000 --> 01:17:40.400
know how to measure like we have kind of a program for know for like figuring out where

01:17:40.480 --> 01:17:46.400
quantum phenomena are occurring, basically, in terms of kind of collective quantum phenomena

01:17:46.400 --> 01:17:49.920
and entanglement and stuff like that. And I think like that's probably something

01:17:49.920 --> 01:17:54.080
like we'll be able to measure. It really depends on like whether we'll be able to do kind of non

01:17:54.080 --> 01:17:57.520
invasive measurements of that. But I would expect that to be basically answered. I think it's

01:17:57.520 --> 01:18:02.080
something we can figure out. But yeah, I have no idea what the answer will be, but pretty exciting,

01:18:02.080 --> 01:18:07.600
I think. I agree. And you know, the more I think about it, I'm simply agnostic to this idea. But

01:18:08.160 --> 01:18:12.000
taking into consideration that there are credible reports of people achieving

01:18:12.000 --> 01:18:16.880
reincarnation. I mean, you can judge the credibility yourself. But you know,

01:18:16.880 --> 01:18:21.840
I consider them credible, at least, then there is there is some there is some

01:18:23.840 --> 01:18:30.560
there is some evidence that a measure of substrate independence is possible. So but like I said,

01:18:30.560 --> 01:18:36.000
you may not be able to upload yourself exactly as you are into the computer. But that really

01:18:36.000 --> 01:18:41.440
depends on what your definition of what you are. If you if you say like, well, I'm the causal

01:18:41.440 --> 01:18:47.840
structure, the water, then that thing might be computationally reducible. And you might be able

01:18:47.840 --> 01:18:54.080
to just simply, you know, upload yourself to any substrate that supports that supports evolution

01:18:54.080 --> 01:19:00.800
of causal structure. But your specific life experience, specific specificity of what it means

01:19:00.800 --> 01:19:05.360
to be you, that seems to be that like, you know, like, at least from this perspective, that might be

01:19:06.000 --> 01:19:11.680
always private to you. That like, if you imagine you merged with another being like Project 2501

01:19:12.240 --> 01:19:19.680
situation and goes in the shell, then you don't experience that the Project 2501 wouldn't

01:19:19.680 --> 01:19:24.480
experience you as you, he would just experience you and the Project 2501 as a one system.

01:19:25.280 --> 01:19:30.880
Right. So the smaller system has always been only only you and that experience will always be

01:19:31.680 --> 01:19:36.400
private, which is kind of funny because it also says that, you know, the God isn't really watching

01:19:36.400 --> 01:19:43.840
you that carefully because it can't. Your faults are private and your real your your there's

01:19:43.840 --> 01:19:49.200
something private to your to your existence that cannot be known. Yeah, from that perspective.

01:19:49.280 --> 01:19:54.960
Yeah, I mean, it makes sense to me. I mean, you know, I like to make a lot of analogies to like

01:19:54.960 --> 01:19:59.040
how, you know, what happens in computers, because those are some kind of really complex systems

01:19:59.040 --> 01:20:03.440
that we understand really well. But, you know, if you imagine you're playing some video game,

01:20:03.440 --> 01:20:08.480
there's like a boundary between, you know, what, what, you know, you'll experience the game and

01:20:09.200 --> 01:20:14.960
the code that's kind of underlying that. And there's an interface like, you know, between you and

01:20:15.040 --> 01:20:19.680
the reality of the game. And because of that interface and the way it works, you're limited

01:20:19.680 --> 01:20:24.880
in like what can ever be observed or measured, like, you know, there's certain things through

01:20:24.880 --> 01:20:28.080
the interface of the game, you never be able to measure. And I think it's probably similar, you

01:20:28.080 --> 01:20:34.800
know, maybe, you know, our interface to reality or whatever things we can't actually measure due

01:20:34.800 --> 01:20:40.240
to that, basically. But I don't know, I don't know. I honestly think that the because the main

01:20:40.240 --> 01:20:44.960
problem here, right, like this is where I have hoped that we actually can understand fully the

01:20:44.960 --> 01:20:50.560
nature of reality is that the things you can measure depend on your generative model.

01:20:52.400 --> 01:20:57.440
In a sense that the first of all, there's a okay, there's putting aside the fact that we need to

01:20:57.440 --> 01:21:02.560
develop technology to be able to measure something. First, we need to know what to measure. So as we

01:21:02.560 --> 01:21:06.880
develop more understanding, more integrated understanding of the of the world, we're figuring

01:21:06.880 --> 01:21:12.800
out how to extract more information out of existing data. Right, you can look at a picture of

01:21:13.920 --> 01:21:18.880
the universe. And as we progress in time, you know, we measure more and more complex aspect

01:21:20.640 --> 01:21:25.120
of the universe from effectively the same kind of picture, the same kind of, I mean, you know,

01:21:25.120 --> 01:21:28.880
our technology to take pictures improved, I mean, what the picture literally going up and looking

01:21:28.880 --> 01:21:36.320
at the stars, as our models improve, our ability to measure improves. So it's a kind of a code

01:21:37.840 --> 01:21:45.360
dependent relationship. So, and there seems to be no bound on our ability to

01:21:46.800 --> 01:21:52.560
increase the complexity of our generative model, so we can approximate the outside world more and

01:21:52.560 --> 01:21:58.800
more accurately or have better and better models of it. And then we'll figure out new things to

01:21:58.800 --> 01:22:04.480
measure. And then we'll just always keep going on. Right. Yeah, yeah, that makes sense. Yeah.

01:22:06.240 --> 01:22:10.800
Okay, cool. You know, actually, so there was one more part of the book I actually wanted to

01:22:10.800 --> 01:22:15.360
get through. I think we'll at least try to get through a little bit of chapter eight, which is

01:22:15.360 --> 01:22:21.680
about starting to get into kind of the quantum side of things. And like how, yeah, how does

01:22:21.680 --> 01:22:27.760
quantum mechanics actually affect the behavior of electrons and metals and then affect things we

01:22:27.840 --> 01:22:32.640
can't measure, right? Like, you know, conductivity. I mean, it doesn't actually, we don't cover that

01:22:32.640 --> 01:22:38.080
till until pretty later in terms of like the measurable stuff. But the kind of beginning of

01:22:38.080 --> 01:22:45.120
this is dealing with the idea of a periodic potential. So because like we have a crystal

01:22:45.120 --> 01:22:52.720
lattice where you have atoms in this array in three dimensions, where from whatever atom you're

01:22:52.720 --> 01:22:59.200
looking at, the lattice looks the same, well, each of those atoms also is like has its own little

01:22:59.200 --> 01:23:04.960
potential energy. Like if you imagine that each of those atoms is a little planet, and you're like,

01:23:04.960 --> 01:23:09.680
and you're the moon, right, you could be sitting there and orbiting one of those planets, or you

01:23:09.680 --> 01:23:14.320
could be kind of moving in between them and kind of slingshotting around a bunch of those little

01:23:14.320 --> 01:23:19.280
planets. But the important thing is that the potential energy or the force that you'll see

01:23:19.280 --> 01:23:24.640
when you're moving along is periodic. And that if you take a step in one direction,

01:23:24.640 --> 01:23:30.080
that's the right length, and the right length being one of the lattice vectors,

01:23:30.080 --> 01:23:35.280
then you'll see exactly the same force as you did before. And so that's like what this equation

01:23:35.280 --> 01:23:43.920
8.1 is saying. If you go to your page 132 in the Ashcroft Merman, 8.1 says you have little r plus

01:23:43.920 --> 01:23:49.280
big r, lowercase r plus capital r, u of r of little r plus big r is equal to u of little r.

01:23:49.920 --> 01:23:56.320
And so big r there is the step that you take. And big r has to be a linear combination of

01:23:56.320 --> 01:24:04.400
the lattice vectors. And if you take a step of that kind, you'll end up at a point that looks

01:24:04.400 --> 01:24:09.760
exactly the same as where you were before. And by looks the same, that means that you'll experience

01:24:09.760 --> 01:24:14.560
exactly the same force as where you were before. So you could think of it almost as if you're in

01:24:14.560 --> 01:24:20.160
this weird like house of mirrors, I guess, where when you walk far enough in any direction, you

01:24:20.160 --> 01:24:24.240
come back to kind of where you started, that's that's how it would feel to be a crystal, I mean

01:24:24.240 --> 01:24:30.320
to be an electron in a crystal. It makes me think of like jump gates in space, you know, like your

01:24:30.320 --> 01:24:34.640
spaceship in space, and there are these jump gates that if you if you get into one and parachutes

01:24:34.640 --> 01:24:39.200
you into it, it propels you exactly where you need to go to get exactly the same boost on the other

01:24:39.520 --> 01:24:46.400
end. Jump gates? Yeah, I'm not actually familiar with that. What was that? I was like in sci-fi,

01:24:46.400 --> 01:24:51.280
you often have the situation where a spaceship just goes into some structure that accelerates it

01:24:51.280 --> 01:24:57.200
to some high speeds. So this is, so it's a point of, you know, some kind of high potential that

01:24:57.200 --> 01:25:03.040
gives you velocity. So you jump it, you're jumping between these places that give you

01:25:03.680 --> 01:25:11.520
the potential boost to travel between them. So for example, Stargate is an example of that,

01:25:11.520 --> 01:25:17.200
and the idea is that you go through this portal that drops you into a stable wormhole that

01:25:17.200 --> 01:25:23.360
brings you to a predictable place. Also the Expanse, I think it was like the later seasons,

01:25:23.360 --> 01:25:29.760
they also had Stargates. Oh, I'm actually watching the Expanse now. I'm like a season four, I think.

01:25:29.760 --> 01:25:36.480
Yeah, it's a good show. Yeah, it is great. Well, because I remember they, yeah, they discover

01:25:36.480 --> 01:25:43.040
like this big kind of portal, but it's like a portal to many different worlds or galaxies or

01:25:43.040 --> 01:25:48.240
whatever, wherever they go. Yeah, they're in a universe that's like a little bit different than

01:25:48.240 --> 01:25:52.960
Stargate, but I think it's like the same general concept. So it's kind of like Stargate, you walk

01:25:52.960 --> 01:25:57.920
into that, and on the other end, there's another Stargate that just propels you forward, right?

01:25:57.920 --> 01:26:04.240
That's what effectively this model looks like. Yeah, okay, yeah. So I mean, if you ever played the

01:26:04.240 --> 01:26:09.760
video game portal, right, and you put a blue portal on one wall, and then you put an orange

01:26:09.760 --> 01:26:14.240
portal on another wall, and then you could just kind of walk between, you could walk through

01:26:14.240 --> 01:26:18.320
the blue portal and go back through the orange one, you could keep walking the same direction,

01:26:18.320 --> 01:26:23.840
and just keep seeing what you saw before, that's what it would be like to be an electron in a crystal.

01:26:24.800 --> 01:26:29.280
Because of this periodic potential, you keep going and you keep seeing the same thing, basically.

01:26:29.840 --> 01:26:34.800
So yeah, it's pretty fun to think about that on this microscopic level, it is a pretty strange

01:26:35.520 --> 01:26:40.560
world, right, where you have this like infinite, I mean, it's not actually infinite, right, but it

01:26:40.560 --> 01:26:46.400
would seem infinite to the electron because the crystal is really large on that length scale, but yeah.

01:26:46.800 --> 01:26:52.000
But so the electron is just moving in these periodic potentials. So from its perspective,

01:26:52.000 --> 01:26:58.880
effectively, kind of like nothing changes, like, or it's sort of gets accelerated from one part

01:26:58.880 --> 01:27:04.400
to the other, where it gets the same kind of acceleration. So it would be like experiencing,

01:27:04.400 --> 01:27:10.000
you know, like I'm thinking of like a pebble rolling in a gravitational well, just experiencing

01:27:10.080 --> 01:27:16.160
the sort of sinusoidal acceleration. Yeah, I mean, so that's basically right. I mean,

01:27:16.160 --> 01:27:19.600
of course, like that would be like the classical way of thinking about it, whereas in reality,

01:27:19.600 --> 01:27:23.920
we have to like say, okay, what's going to be the wave function of the particle in this

01:27:23.920 --> 01:27:28.320
periodic potential? That's basically right, that it just keeps going through. Now, the thing is

01:27:28.320 --> 01:27:34.560
that while the landscape is the same, as when it goes through, when it goes enough distance to

01:27:34.560 --> 01:27:39.920
kind of come back to the same place, the landscape is the same, but it's not exactly the same.

01:27:39.920 --> 01:27:44.400
Where it is in that landscape, you kind of change. So in other words, you're walking in this

01:27:44.400 --> 01:27:49.040
periodic room, but like maybe you're kind of walking on the diagonal. And so each time you

01:27:49.040 --> 01:27:54.160
cross through the wall, you end up starting at like a place a little bit different. And so that's

01:27:54.160 --> 01:27:57.600
kind of what it would be like for the electron. And so eventually, if it keeps going, it might

01:27:57.600 --> 01:28:02.000
actually scatter, meaning it might actually hit, you know, a nucleus or something like that. And

01:28:02.000 --> 01:28:06.800
so that's when things kind of, when at least its motion will change is that it'll, you know,

01:28:06.800 --> 01:28:11.360
eventually scatter off of something. Well, I just said like this trippy thought that this is what

01:28:11.360 --> 01:28:16.960
moving in space must actually be like at the fundamental level that, you know, I'm copying myself

01:28:18.560 --> 01:28:24.560
from one portion of the hypergraph to another in the same way. This is sort of like the wave

01:28:24.560 --> 01:28:30.400
function of an electron localizes it in one space or another when in reality it's not actually a

01:28:30.400 --> 01:28:36.400
pebble moving some fields. It's just like, it's sort of manifesting itself in the space

01:28:36.400 --> 01:28:42.640
given by the probabilities of the defined by the potentials. Right. I see. Yeah. Yeah. I mean,

01:28:42.640 --> 01:28:47.360
that's interesting. Right. Like, you know, am I the same person as I was, you know, a few seconds

01:28:47.360 --> 01:28:52.240
ago, or if, you know, if I'm moving, you know, things like that, because we could think of all

01:28:52.240 --> 01:28:58.160
these particles that are moving as just ripples and some kind of field, I guess. Well, so this

01:28:58.160 --> 01:29:02.480
actually relates, I guess, to kind of where it's going, because instead of just thinking of this

01:29:02.800 --> 01:29:07.440
as an electron being a little ball that's shooting around through this house of mirrors,

01:29:07.440 --> 01:29:13.200
as I call it, or through the portal video game, it's actually the electron is a wave, right.

01:29:13.920 --> 01:29:18.800
And so we think of the electron itself as being a function. So now we have two functions, right.

01:29:18.800 --> 01:29:23.600
There's the potential energy function, which they're calling you capital U for the potential

01:29:23.600 --> 01:29:29.520
energy function. And then there's the wave function of the electron. So you can think of the potential

01:29:29.520 --> 01:29:35.360
energy function as like a rolling hill. I can imagine you're sledding, you know, on some, you

01:29:35.360 --> 01:29:40.960
know, sledding in the snow, and the bumps kind of go up and down and up and down in all directions.

01:29:40.960 --> 01:29:44.800
There's kind of different bumps. And that's the potential energy function. And that's the thing

01:29:44.800 --> 01:29:48.800
that's periodic, right. So if you sled far enough, you'll come back to a place that looks exactly

01:29:48.800 --> 01:29:54.880
like where you started. But now, instead of just being on my own on a little sled at one point

01:29:54.880 --> 01:30:01.520
in space, I'm actually kind of this amorphous blob that's sledding on the hill. So I'm not just in

01:30:01.520 --> 01:30:06.320
one place, I'm kind of spread out in some area, basically. And that's really what the electron

01:30:06.320 --> 01:30:12.800
is like. It's kind of this amorphous blob that's sledding through the crystal in the places where,

01:30:12.800 --> 01:30:17.360
you know, when it's going down a hill, it gets faster. And when it's going up a hill, it gets

01:30:17.360 --> 01:30:23.200
slower. But it's not just going down a hill or going up a hill at any one time, because it's

01:30:23.200 --> 01:30:30.080
in different places. And one part of the electron cloud could be going uphill and one part could

01:30:30.080 --> 01:30:34.320
be going downhill, although it does kind of have a well-defined velocity, which is interesting.

01:30:34.320 --> 01:30:38.880
You could think of that electron, which is this cloud spread out in the atom, as having a velocity

01:30:38.880 --> 01:30:45.200
and going in some direction, basically. And so how the thing is actually modeled physically is,

01:30:45.200 --> 01:30:51.520
you know, of course, using Schrodinger's equation, which is this 8.2 in the book on page 133.

01:30:51.840 --> 01:30:58.800
And so that says on the left hand side, well, there's kind of three parts of it, because h psi

01:30:58.800 --> 01:31:03.840
equals something which is equal to e psi. But you should ignore the h psi for a second. And in the

01:31:03.840 --> 01:31:10.880
middle, we have grad squared plus u. I'll ignore the pre-factors. You have grad squared plus u,

01:31:10.880 --> 01:31:16.320
all multiplied by psi is equal to e psi. So that's like a partial differential equation,

01:31:16.880 --> 01:31:22.800
right? And the grad squared is kind of measuring the curvature. And so that's like,

01:31:23.760 --> 01:31:31.360
at any point in the electron cloud, is that like kind of more dense than its surroundings or less

01:31:31.360 --> 01:31:36.880
dense than its surroundings? So in other words, if the electron is really this cloud of kind of

01:31:36.880 --> 01:31:42.400
density and space, and if one point in that cloud is dense compared to its surroundings,

01:31:42.400 --> 01:31:47.440
then the grad squared of psi will be negative there. And if that point in the cloud is less

01:31:47.440 --> 01:31:51.600
dense compared to its surroundings, then the grad squared will be positive there, okay? So that's

01:31:51.600 --> 01:31:57.920
called the curvature. And so you do, and then there's just u, and that's the capital u is the

01:31:57.920 --> 01:32:04.240
potential. So you multiply that by psi. And then all of that has to be equal to some number e times

01:32:04.240 --> 01:32:08.960
psi, and e is the energy. So that's like, that's the Schrodinger equation, right? And that's what

01:32:08.960 --> 01:32:14.640
actually governs like what the shape of that cloud basically looks like. And then the interesting

01:32:14.640 --> 01:32:19.280
thing, the thing I wanted to get to is what's called Bloch's theorem. And what Bloch's theorem says

01:32:19.920 --> 01:32:26.000
is that not only is the landscape the snow that you're sledding on periodic, but also the cloud

01:32:26.000 --> 01:32:34.640
that's sledding on the electron cloud is also periodic. And so it, the electron itself is kind

01:32:34.720 --> 01:32:42.800
of stretches out in all directions actually, kind of infinitely. And if you were to take a step in

01:32:42.800 --> 01:32:49.760
one direction of size big R, where big R is some lattice vector, then the electron cloud would

01:32:49.760 --> 01:32:55.200
look exactly the same there as in your original point kind of, except modulated. This is actually

01:32:55.200 --> 01:33:01.520
important, not exactly the same. It's periodic and then modulated by a complex exponential e to the

01:33:01.520 --> 01:33:06.800
ikr. So there's like kind of an additional ripple on top of that periodicity, I guess. Yeah.

01:33:09.760 --> 01:33:14.240
Wow, that's a great explanation. Max, you should really start as cool, honestly.

01:33:15.600 --> 01:33:18.720
Forget this engineering career. You should be a professor.

01:33:19.920 --> 01:33:24.080
Well, yeah, maybe that's in the card someday. I enjoy going through these because it helps me

01:33:24.080 --> 01:33:29.680
understand it. I actually pay a lot more attention when I'm trying to digest it in order to kind of

01:33:29.680 --> 01:33:35.280
explain it than when I'm just reading it myself. But yeah, that was kind of block's theorem.

01:33:36.720 --> 01:33:41.840
Right, was that the electron cloud is periodic and it has the same periodicity as the potential

01:33:42.720 --> 01:33:48.720
with this added ripple on top of it, basically. So this added ripple on top, like in some sense,

01:33:49.840 --> 01:33:56.240
so because the electron is moving in the potential, it sort of takes the shape of the

01:33:56.240 --> 01:34:03.520
potential. But this added ripple also says that it has some characteristic of its own, right?

01:34:04.080 --> 01:34:06.560
Yeah, yeah, yeah, I think that's a good way to think about it. Yep.

01:34:10.160 --> 01:34:16.720
So, well, it even actually, both parts have some kind of, well, let's see. Right, I guess, yeah,

01:34:16.720 --> 01:34:25.600
both parts, both the thing, the part of it that's, let's call it the lattice periodic part, and then

01:34:26.160 --> 01:34:32.720
the ripple part, I guess. So like, both of those parts together have to satisfy the Schrodinger

01:34:32.720 --> 01:34:38.000
equation as a whole. So when you multiply those two things together, that object is called the

01:34:38.000 --> 01:34:43.360
wave function, and that's the thing that has to satisfy the Schrodinger equation. But the ripple

01:34:43.360 --> 01:34:48.240
doesn't really have any particular periodicity. It could have, I mean, it kind of does because

01:34:48.400 --> 01:34:57.280
it depends on the whole bulk crystal, which is huge. But the lattice periodic part depends a lot

01:34:57.280 --> 01:35:02.000
on the microscopic structure of the crystal. So you have these two things that get multiplied

01:35:02.000 --> 01:35:07.680
together, one that depends on the size of the whole bulk crystal, and one that just depends

01:35:07.680 --> 01:35:13.360
on the size of the local cell in the crystal, basically. So what I'm trying to say is, if you

01:35:13.360 --> 01:35:19.520
think about the, you know, electron as a kind of like a vortex in some kind of graph, right, like

01:35:19.520 --> 01:35:25.440
Wolfram you're thinking, then this equation seems to say that basically you can separate the wave

01:35:25.440 --> 01:35:30.880
function of an electron moving through that kind of field as the part that is reflective of the

01:35:31.600 --> 01:35:37.360
vessel it's contained in, and the part that's somewhat intrinsic to it.

01:35:38.000 --> 01:35:47.840
Right. Yeah, that's a good question. I honestly, like, yeah, I'm not totally sure if like,

01:35:48.400 --> 01:35:54.640
if like what part should be thought of as like intrinsic versus reflect. I guess I think that's

01:35:54.640 --> 01:36:01.200
kind of right in that the... Well, the thing about this way, like if an electron is moving in a

01:36:01.200 --> 01:36:10.240
different potential, then that part of, there will be a part of it that will be reflective of the

01:36:10.240 --> 01:36:15.280
potential. It will diffuse in the potential, in the way that the potential allows it to diffuse.

01:36:16.400 --> 01:36:19.920
Does the space for the fractal to unpack, so to speak, and take some space?

01:36:20.960 --> 01:36:26.000
But there is also the thing that makes the fractal fractal, that makes it an actual electron.

01:36:26.720 --> 01:36:30.960
Right. Yeah, I guess that's right. Yeah, because when you go to a different crystal

01:36:30.960 --> 01:36:37.200
and a different potential, basically the part of the wave function that's the lattice periodic part

01:36:37.200 --> 01:36:43.680
will change a lot, whereas you'll always have that complex exponential function multiplying it,

01:36:43.680 --> 01:36:47.520
which is kind of, yeah, I guess you're right, that's kind of characteristic of the fact that it's an

01:36:47.520 --> 01:36:52.560
electron. And you know, the fact that the complex exponential is a rotation in the complex plane,

01:36:52.560 --> 01:36:57.040
that also seems to be like, like that's a, that's a, to me, that always felt like that's a computation

01:36:57.040 --> 01:37:02.800
in a different, in a different dimension, so to speak, right, or orthogonal to whatever it is.

01:37:02.800 --> 01:37:07.760
So it's a moving for space, unpacking into space, that's one, one dimension of computation, but

01:37:07.760 --> 01:37:16.400
like, you know, at some angle to that, there's the actual computation, the, the, the, the actual

01:37:16.400 --> 01:37:22.800
vortex that, that makes the electron, electron. Yeah. Yeah. So that's actually super important,

01:37:22.800 --> 01:37:27.440
the fact that, right, right, the fact that the complex exponential can be thought of as a rotation

01:37:27.440 --> 01:37:32.720
in the complex plane, because the next thing on this, like, page 134 is the proof of Bloch's

01:37:32.720 --> 01:37:36.960
theorem, and it uses that, the fact that the complex exponential is a rotation in the complex plane,

01:37:37.920 --> 01:37:45.120
because if you imagine a complex exponential function, like e to the i kx, where x is, you know,

01:37:45.120 --> 01:37:51.520
or k is just some number, and x is like the x-axis, then what does that look like as we travel along

01:37:51.520 --> 01:37:59.280
the x-axis? Well, e to the i kx kind of looks like a spiral that's going counterclockwise around

01:37:59.280 --> 01:38:06.560
the x-axis. If, if instead of like the y and z-axis, we had like the imaginary part of e to the i kx,

01:38:06.560 --> 01:38:10.160
the real part of e to the i kx and the imaginary part, like we're just plotting the real part and

01:38:10.160 --> 01:38:15.840
the imaginary part, and, and now as we go along the x-axis, we see this spiral that goes in a,

01:38:15.840 --> 01:38:20.880
in a counterclockwise direction, and the interesting thing about that spiral is that if you translate

01:38:20.880 --> 01:38:27.520
it along x, if I say x, I'm going to replace x with x plus one and just slide the whole spiral

01:38:27.520 --> 01:38:34.880
around along on the x-axis, well, if I then rotate the spiral, then I can get it to coincide with

01:38:34.880 --> 01:38:39.680
what it looked like originally. So you can always kind of, you can undo a translation of a spiral

01:38:39.680 --> 01:38:48.640
by a rotation, okay? And so that, or another way of saying it, that is that complex exponentials are

01:38:48.640 --> 01:38:54.560
these, or these spirals we were talking about are eigenfunctions of the translation operator,

01:38:54.560 --> 01:38:59.120
because what an eigenfunction is, it's something that when you apply an operator,

01:38:59.120 --> 01:39:03.760
you get back the same function, but multiplied by some constant. And so in other words, these

01:39:03.760 --> 01:39:07.200
complex exponentials, they're eigenfunctions of the translation, because when you translate them,

01:39:07.200 --> 01:39:11.200
you get back the same thing that's multiplied by a constant, or in other words, rotated in the

01:39:11.200 --> 01:39:19.120
complex plane. Yeah. But you know, one thing about the complex plane as a construction that

01:39:19.120 --> 01:39:23.280
always struck me, the thing that was kind of like an enlightening moment, is that when I started

01:39:23.280 --> 01:39:29.520
thinking about this, is that it's a construction that allows you to get out of the real plane into

01:39:29.520 --> 01:39:34.080
some other space. So you say like, well, I would like to describe part of my process in a space

01:39:34.080 --> 01:39:40.080
that is nowhere incidental on the real space. So it's kind of like an effect in this, you know,

01:39:40.080 --> 01:39:47.360
orthogonal, orthogonal to reality, so to speak. Then all you have to do is to do this rotation,

01:39:47.360 --> 01:39:53.920
and suddenly you have a lot of space to do something else. Right. Yeah, it is interesting,

01:39:53.920 --> 01:39:58.480
in a lot of times. That is preserved by translations in the real space, as you just said.

01:39:58.480 --> 01:40:04.880
Right? Right. So the essence of that thing, that I suddenly have a process, kind of like

01:40:05.120 --> 01:40:10.160
that can be going on, there could be stuff happening there, and I can describe it in this

01:40:10.160 --> 01:40:16.160
other space, and I can translate my object in the real space, and that thing is going to be unaffected.

01:40:16.160 --> 01:40:22.160
The reference frame changes. So I may need to do a little bit of jiggling to really see

01:40:22.160 --> 01:40:27.440
that this is the same thing, but it is the same thing. Yeah. Yeah, it really is very, you know,

01:40:27.440 --> 01:40:32.240
it really is really, really strange. I mean, because like, yeah, a lot of times when we're

01:40:32.240 --> 01:40:37.920
given some physical system that has a very nicely kind of prescribed set of coordinates,

01:40:37.920 --> 01:40:43.760
like a bunch of masses on springs or whatever, or voltages, and then it kind of has these natural

01:40:43.760 --> 01:40:49.040
coordinates of, you know, X, Y, and Z, or the voltages on different conductors, then like the

01:40:49.040 --> 01:40:53.200
first thing we'll do in physics is we'll introduce all these other coordinates by going to a complex

01:40:53.200 --> 01:40:58.800
space, and so now all of a sudden we have twice the number of numbers, right, because for every X

01:40:58.800 --> 01:41:03.840
we now have an imaginary part, and those imaginary parts are not real, right, like they're both in

01:41:03.840 --> 01:41:09.520
the mathematical in the actual sense, like they don't exist anywhere in nature that we know about,

01:41:09.520 --> 01:41:14.160
but they just make it easier to kind of predict what's going to happen. And so instead of having

01:41:14.160 --> 01:41:19.440
a sinusoid, you have this spiral, which to me has always been very strange that, you know,

01:41:19.440 --> 01:41:25.120
that's how kind of how we end up doing things. Think about it this way. If I give you a piece of

01:41:25.120 --> 01:41:31.760
memory, right, a computer memory, I'm just going to give you a memory dump. It absolutely makes

01:41:31.760 --> 01:41:37.600
no sense whatsoever to you unless, you know, what is the operating system that this, say, program

01:41:37.600 --> 01:41:42.880
is running on? What are the rules? What's the virtual architecture? So where is this architecture

01:41:42.880 --> 01:41:47.760
that allows you to execute that program? Well, it's not in the hardware. It's not in the program

01:41:47.760 --> 01:41:53.200
itself. Where is it? Well, you can't find it anywhere. It's a causal structure that exists

01:41:53.200 --> 01:41:59.520
in a space that's orthogonal to reality. That's the platonic realm, effectively. So in some sense,

01:41:59.520 --> 01:42:04.480
this construct, to me, this construction is to basically say like, well, I need this other space,

01:42:04.480 --> 01:42:11.120
this platonic space, to describe part of the process, because it's nowhere, no, it's part of

01:42:11.120 --> 01:42:19.360
a process that's not actually dependent on the physical part of the system. It's something else.

01:42:19.360 --> 01:42:26.160
So complex plane is a construction that gives you ability to go there. And this is the nice thing

01:42:26.160 --> 01:42:33.120
that all you have to do is to multiply by i, and suddenly you're out of whatever real space you've

01:42:33.120 --> 01:42:39.600
defined for yourself. Right. Yeah, I see. I kind of see that way of looking at it. You know what I

01:42:39.600 --> 01:42:44.720
always wanted to do is say, all right, well, if you're going to give me an equation, a differential

01:42:44.720 --> 01:42:50.320
equation, and treat x as a complex variable, then why don't I just turn that into two equations in

01:42:50.320 --> 01:42:56.720
real variables, right? Because it must be somewhere that other variable, right? So we can just treat

01:42:56.720 --> 01:43:02.000
it as a real difference. And you can think of all of the complex analysis in this way that whenever

01:43:02.000 --> 01:43:06.720
you see an i, you just replace it by a matrix, like a two by, a little two by two matrix. And then

01:43:06.720 --> 01:43:11.200
when you have a matrix of complex numbers, you can just replace that by a matrix that's twice as

01:43:11.200 --> 01:43:16.560
large and you get back to real numbers. But I think your way of looking at it is also interesting,

01:43:16.560 --> 01:43:21.680
maybe better, that instead of trying to look for those complex numbers somewhere in reality,

01:43:21.680 --> 01:43:26.640
you just think of it as like, there's like another way of thinking of things that isn't,

01:43:26.640 --> 01:43:32.640
like, actually in, you know, better than reality anywhere, you know, either hardware or software,

01:43:32.640 --> 01:43:39.920
that's just kind of this separate world, I guess. Sorting algorithm is an ideal that

01:43:40.560 --> 01:43:47.520
or platonic form that exists independent of any kind of realization. It will always exist,

01:43:47.520 --> 01:43:54.240
it always has existed, it could not exist, it's just there, right? It wasn't invented, it's just

01:43:54.240 --> 01:44:00.240
a thing. So that's how I think about it, like from this angle, from my computer science background,

01:44:00.240 --> 01:44:05.360
like, and the reason I think about it is just because once I started thinking about it this way,

01:44:05.360 --> 01:44:10.560
it all started to make sense instead of just memorizing rules and, you know, just drilling

01:44:10.560 --> 01:44:17.680
it into my head until I can compute with it. It's like, oh, I get it. Right, yeah, yeah, makes sense,

01:44:17.680 --> 01:44:25.040
yeah. All right, well, so I'm just gonna kind of finish the like, I guess, I don't know what to

01:44:25.040 --> 01:44:31.280
call it, lecture portion with this kind of final thought on on Bloch's theorem, which is basically

01:44:31.280 --> 01:44:36.240
a proof of Bloch's theorem. And, and Bloch's theorem was the thing that said that when you had

01:44:36.240 --> 01:44:43.680
the periodic potential or the periodic landscape that you're sweating on, then the wave function

01:44:43.680 --> 01:44:49.200
or the electron cloud is also periodic with the same periodicity in all directions. And, and the

01:44:49.200 --> 01:44:53.680
proof this, I really like this first proof, I give two, but I'm not going to go into the second one,

01:44:53.680 --> 01:44:57.760
but the first one I think is pretty, pretty nice and elegant. And what it says is that, well, first

01:44:57.760 --> 01:45:03.120
of all, we were going to talk about this translation operator. And what it does, it just takes a

01:45:03.120 --> 01:45:10.960
function and moves it kind of in like the x, y, and z directions. So the translation operator,

01:45:10.960 --> 01:45:15.120
it also has like another kind of argument there that's hidden, which is what vector you're going

01:45:15.120 --> 01:45:19.600
to translate the function by, but its input is really the function. And then it's kind of,

01:45:19.600 --> 01:45:24.880
other side argument is the translation vector. And then its output is the translated function,

01:45:24.880 --> 01:45:30.880
which is just the function. But if you, if now if you input some point in space, you would get

01:45:30.880 --> 01:45:35.280
the output of the original function at a different point in space, you know, translated.

01:45:36.080 --> 01:45:41.600
And so the, the important thing here is that when you take the, when you take Schrodinger's

01:45:41.600 --> 01:45:46.400
equation, and you say, let's say I had a solution to Schrodinger's equation, I had a solution to

01:45:46.400 --> 01:45:50.800
this partial differential equation that includes kind of the curvature of the function and the

01:45:50.880 --> 01:45:58.880
potential energy. And let's say I translated that solution. Let's see. So, or actually,

01:45:58.880 --> 01:46:02.560
sorry, maybe that's not the right way to say it. If you apply the translation operator,

01:46:02.560 --> 01:46:10.720
I guess, on both sides of the equation, then what happens is you see that basically the,

01:46:10.720 --> 01:46:15.040
the translation operator kind of commutes with the Hamiltonian in that you can,

01:46:15.120 --> 01:46:20.800
you can translate this function psi either before you apply this differential operator,

01:46:20.800 --> 01:46:25.680
which is the curvature plus the potential, or you could first apply that operator and then

01:46:25.680 --> 01:46:30.240
translate the function and you get out the same thing. And that kind of is something you could

01:46:30.240 --> 01:46:34.640
see if you, if you just write out Schrodinger's equation and you apply this translation operator.

01:46:35.680 --> 01:46:39.680
And then what happens in, is something we know kind of from quantum mechanics is whenever two

01:46:39.760 --> 01:46:46.800
operators commute, they share a basis of, of eigenfunctions. An eigenfunction is,

01:46:46.800 --> 01:46:53.120
is just something that when I apply an operator to it, if, if, if psi is an eigenfunction of h,

01:46:53.120 --> 01:46:59.040
then when I apply h to psi, I get back psi multiplied by some constant. So we, we now know

01:46:59.040 --> 01:47:04.960
that because the Hamiltonian commutes with the translation operator, that the eigenfunctions

01:47:05.040 --> 01:47:10.240
of the Hamiltonian and the translation operator are the same. But we also know what the eigenfunctions

01:47:10.240 --> 01:47:16.160
of the translation operator are, because we know that when we like translate these, these complex

01:47:16.160 --> 01:47:22.880
exponentials, or, or periodic functions, right, when we, when we, or actually you're right,

01:47:22.880 --> 01:47:30.000
when we take any like periodic function multiplied by a complex exponential, we get back the same

01:47:30.000 --> 01:47:34.320
periodic function multiplied by some constant, right, because whenever you translate that complex

01:47:34.320 --> 01:47:39.280
exponential, you just extract as kind of a scalar multiple. And so the idea here is that

01:47:39.280 --> 01:47:43.440
those eigenfunctions are the same. And so now we know what the eigenfunctions of the Hamiltonian

01:47:43.440 --> 01:47:47.920
are. They have to be these, these functions that when we translate them by lattice vectors,

01:47:47.920 --> 01:47:53.440
we get back the same thing multiplied by some, by some complex number. And so those end up being

01:47:53.440 --> 01:47:58.800
these kind of block form functions where you have a complex exponential multiplied by a periodic

01:47:58.800 --> 01:48:02.800
function. So that might have not been the best explanation, but that's, that's kind of the idea

01:48:02.800 --> 01:48:07.440
is that using the fact that the translation operator commutes with a Hamiltonian, and the

01:48:07.440 --> 01:48:12.480
Hamiltonian itself is periodic, you can figure out what, you know, what the properties of the

01:48:12.480 --> 01:48:16.400
eigenfunctions are of the Hamiltonian. And those, those eigenfunctions of the Hamiltonian are going

01:48:16.400 --> 01:48:20.960
to be super important because those are the energy levels of the, of the electrons in the crystal kind

01:48:20.960 --> 01:48:31.120
of. Yeah. So yeah, I don't know if that's, that's something that, that, that proof relies a lot on

01:48:31.120 --> 01:48:36.640
like kind of going through the standard quantum curriculum where you talk a lot about commuting

01:48:36.640 --> 01:48:41.680
operators and their shared eigenfunctions. So maybe, you know, maybe not the most intuitive thing, but

01:48:42.640 --> 01:48:46.320
at least in terms of quantum, it's kind of a nice connection, I think.

01:48:52.240 --> 01:48:55.600
Nice. That's, that's a little bit over my head. I'm not that familiar with the

01:48:55.680 --> 01:49:00.720
standard quantum curriculum, or at least it's been like 10 years since I, since I had it. So

01:49:01.680 --> 01:49:06.800
yeah, but, but, but, but I get the gist, like, especially this, this commuting part, that argument

01:49:06.800 --> 01:49:13.840
is, you, you, you laid it out very clearly. That totally makes sense. Yeah. Yeah. And there's something

01:49:13.840 --> 01:49:18.880
in there that's still kind of mysterious, I think, which is like, why is it that operators that commute

01:49:18.880 --> 01:49:23.440
have like shared eigenfunctions? Honestly, yeah, I don't have a great intuitive kind of grasp of

01:49:23.440 --> 01:49:27.360
that. It's just something that, like, just one of these mathematical facts, I guess, but

01:49:27.920 --> 01:49:32.240
yeah, we'd love to understand it better, honestly, but if it's connected to all these deep things

01:49:32.240 --> 01:49:38.240
in physics, like Neuter's theorem, where all like symmetries are connected with conserved

01:49:38.240 --> 01:49:46.000
quantities and stuff like that. Definitely. Because the fact that they commute, that's a kind of a

01:49:46.000 --> 01:49:52.000
symmetry, right? Right. Well, yeah, it's interesting, because that's like kind of a formal symmetry,

01:49:52.000 --> 01:49:57.600
like in the, in the world of symbols, but then it actually ends up being related to, like, a

01:49:57.600 --> 01:50:03.040
physical symmetry, kind of, in actual, like, in transforming space, which is kind of interesting

01:50:03.040 --> 01:50:17.600
thing about, yeah. I wonder if all of this is going, and maybe it says this in the text somewhere,

01:50:17.600 --> 01:50:24.160
but does crystal structure, does knowing the crystal structure let you predict conductivity,

01:50:24.160 --> 01:50:32.800
kind of like, you know, ceramics and superconductors, and I don't know if there is, if it helps you

01:50:32.800 --> 01:50:37.360
predict that sort of thing, so you can design better materials? Yeah, you know, definitely.

01:50:37.360 --> 01:50:43.120
That's like one of the most important, like, properties, I would say, you know, that this kind

01:50:43.200 --> 01:50:47.600
of, that this theory of, like, solid state physics can predict is the conductivity of,

01:50:48.800 --> 01:50:54.480
of materials, of both, like, metals and semiconductors. And even more importantly,

01:50:54.480 --> 01:51:00.000
like, how that conductivity depends on things you do to the material, like, for example, if you

01:51:00.000 --> 01:51:04.240
change the temperature, the conductivity could change a lot, like, in a semiconductor, like,

01:51:04.240 --> 01:51:07.760
you can go from being an insulator to being a conductor, basically, like, something that doesn't

01:51:07.760 --> 01:51:13.440
conduct, that's something that does. So, yeah, that's like one of the key things to, to look at

01:51:13.440 --> 01:51:27.520
here is, like, conductivity and properties like that. But, yeah, and actually, so it's kind of

01:51:27.520 --> 01:51:33.280
relates to what they get into a little bit later in here is, like, band structure, and that basically

01:51:33.280 --> 01:51:39.520
just has to do with, like, what, what kind of states an electron can be in, in a metal, like,

01:51:39.520 --> 01:51:44.720
because there, there, there end up being, like, because of quantum mechanics in these, like,

01:51:44.720 --> 01:51:50.560
this weird, you know, world of the electron cloud that has to be periodic, there, there are kind of,

01:51:50.560 --> 01:51:55.360
like, speed limits. It's almost like, there's certain, there are certain speeds that it's allowed

01:51:55.360 --> 01:52:01.040
to go, and other speeds that it's just not allowed to go. And so normally, you think of a speed limit

01:52:01.040 --> 01:52:08.000
by being, you can't go over 60 miles an hour here, but in the world of electrons and crystals,

01:52:08.000 --> 01:52:12.400
they're more like weird speed limits where it's like, you're not allowed to go between 60 and 80

01:52:12.400 --> 01:52:16.480
miles an hour, but you're allowed to go lower than 60, and you're allowed to go higher than 80,

01:52:16.480 --> 01:52:20.000
right? So that'll be, like, a pretty weird speed limit. But that's kind of, that's like how it is

01:52:20.000 --> 01:52:25.200
in a semiconductor. And that's, like, kind of, kind of like a band gap, where there's, like, gaps in

01:52:25.200 --> 01:52:30.080
the energy that aren't, that, you know, electrons aren't allowed to exist at that energy, and they

01:52:30.080 --> 01:52:36.160
can exist kind of above and below. And that's, like, the key to, like, seeing, like, why basically

01:52:36.160 --> 01:52:40.800
something can, why something can be a semiconductor that can, like, conduct at one temperature and

01:52:40.800 --> 01:52:46.720
not at another, that if, if basically, if all of the state, like, you think of it as, like, a highway,

01:52:46.720 --> 01:52:50.800
where, like, when there's a bunch of cars on the highway, kind of, all the states are filled,

01:52:51.600 --> 01:52:54.960
and maybe there's, like, a left lane where you're allowed to go fast, and there's, like, a right

01:52:54.960 --> 01:53:01.520
lane where you can't go fast or something. And what it basically depends on is, like, whether,

01:53:01.520 --> 01:53:07.520
if there is an open lane where there's electron can go there, then you can conduct. And if all the

01:53:07.520 --> 01:53:13.040
lanes are full, then you can't, basically. And there, and because of these, like, weird speed

01:53:13.040 --> 01:53:19.280
limits where there's, there's gaps in the, you know, speeds you can travel, it can be really hard to,

01:53:19.280 --> 01:53:25.200
like, accelerate up to, you know, you end up in a situation where you want to accelerate the

01:53:25.200 --> 01:53:30.320
electron to a higher speed, but there's no speed available there because there's a gap in the

01:53:30.320 --> 01:53:35.920
band structure. So that's kind of how these semiconductors work, I guess. Is, is that where

01:53:35.920 --> 01:53:41.920
doping comes in? Or is that something different? Like, does doping give you, does it help cover

01:53:41.920 --> 01:53:48.160
some of the band? Yeah, that's exactly, that's exactly what it does, is it makes new lanes in

01:53:48.160 --> 01:53:53.200
the gap, you know, it makes new energy levels in the gap between the two bands. So that'll be,

01:53:53.200 --> 01:53:58.320
like, saying, like, okay, we had this speed limit where you weren't allowed to go between 88 or between

01:53:58.320 --> 01:54:03.520
60 and 80, but now we're going to add a new kind of little speed that you can go in, in between

01:54:03.520 --> 01:54:08.000
there somewhere. I mean, this is, it's definitely an oversimplification, like, there's a lot of

01:54:08.000 --> 01:54:11.520
complexity, but that's, I think that's, like, a reasonable way to think about it, that it adds

01:54:11.600 --> 01:54:14.480
extra levels in the band gap, basically. Yeah.

01:54:19.520 --> 01:54:26.400
But this is a very classical analogy. Do you think you could, you could make it quantum?

01:54:28.960 --> 01:54:34.640
Yeah, well, so the quantum way to think about it would be if you looked at figure, like,

01:54:35.360 --> 01:54:39.280
let's see, I think if you looked at figure, where is this?

01:54:48.240 --> 01:54:48.960
Here's somewhere.

01:54:53.680 --> 01:54:56.480
Well, for 8.1, not 8.1, actually.

01:54:59.280 --> 01:55:02.000
Oh yeah, it's in the next chapter, actually. Sorry, it's in the next chapter.

01:55:02.720 --> 01:55:10.080
Right. The weak periodic potential. I guess, like, figure 9.1 kind of, right? So,

01:55:10.960 --> 01:55:14.240
yeah, can you guys see figure 9.1, where you have these kind of two, like,

01:55:15.280 --> 01:55:24.800
paraboloids that intersect each other? Yes. Okay. So, what that picture is kind of about is that,

01:55:25.680 --> 01:55:35.840
well, let's see. So, I guess, you can think of k, the x-axis in this figure, k, you can think of

01:55:35.840 --> 01:55:43.280
that as, like, momentum, right? And you can think of the y-axis as the energy. And so, we know that,

01:55:43.280 --> 01:55:48.800
like, the energy, kinetic energy is proportional to the square of momentum, or to the square of speed,

01:55:48.880 --> 01:55:55.120
right? E equals one-half mv squared. So, I mean, I know that still seems kind of

01:55:55.120 --> 01:56:00.880
classical. But that's also true for, you know, Schrodinger's equation. You have a factor of p

01:56:00.880 --> 01:56:08.640
squared, where p is that differential operator derivative with respect to x. And this figure

01:56:08.640 --> 01:56:12.480
is actually, you're supposed to think about it in terms of quantum states. So, instead of, like,

01:56:12.480 --> 01:56:16.640
thinking about a point, you know, a ball that's, like, moving in some direction with a certain

01:56:16.640 --> 01:56:22.000
velocity, when I say it has a momentum of k, you should really think of, like, that as being the

01:56:22.000 --> 01:56:27.200
wave vector, or, like, the frequency of the wave. So, if it has a higher momentum, that means it's

01:56:27.200 --> 01:56:32.000
a higher frequency, or a shorter wavelength, basically. And lower momentum, that means a longer

01:56:32.000 --> 01:56:36.480
wavelength. But you could also think of it as being a ball moving some direction in space,

01:56:36.480 --> 01:56:40.080
or being an electron, like, you know, as a point, kind of moving some direction in space.

01:56:41.040 --> 01:56:46.560
And so, what that paraboloid is, is that's that, like, energy equals one-half mb squared, right?

01:56:47.120 --> 01:56:51.680
The energy proportional to the square of momentum. If you look at the paraboloid that kind of,

01:56:51.680 --> 01:56:57.680
it's where its bottom is, where the y-axis kind of starts out of. But then something,

01:56:57.680 --> 01:57:03.680
like, kind of strange happens, that instead of just the energy increasing as you increase k,

01:57:03.680 --> 01:57:08.080
there's, like, this other paraboloid that starts a little bit over to the right.

01:57:08.960 --> 01:57:14.720
And the reason that basically happens, well, you can kind of think about it in terms of,

01:57:14.720 --> 01:57:19.520
like, one way to think about it is in terms of aliasing, actually, which is something in,

01:57:19.520 --> 01:57:22.160
like, signal processing. And what it has to do with this is that-

01:57:22.160 --> 01:57:23.280
Yeah, I was just thinking about it.

01:57:24.080 --> 01:57:29.040
Yeah, yeah. So, it really does have to do with aliasing. So, if I have a, well, think about

01:57:29.040 --> 01:57:33.120
like this, like, let's say, if you've ever seen a video of somebody recording a helicopter, like,

01:57:33.120 --> 01:57:37.760
on a video, sometimes it'll look like the rotor is spinning, like, really slowly, actually.

01:57:38.080 --> 01:57:42.640
So, or similarly, if you see a recording from a car and you see the hubcap on the car, it looks

01:57:42.640 --> 01:57:47.280
like it's rotating slowly, or sometimes even rotating backwards. And why does that happen?

01:57:47.280 --> 01:57:52.480
Well, it can happen, for example, if the rate that the rotor is rotating at

01:57:52.480 --> 01:57:56.560
is synchronized to the shutter speed of the camera, right? Because if you take a picture,

01:57:56.560 --> 01:58:01.120
every time the rotor has made a full rotation, you'll see it in the same place and it'll just

01:58:01.120 --> 01:58:05.440
look like it's sitting still. Or if you take a picture just a little bit slower than that,

01:58:05.440 --> 01:58:08.960
then every time you take a picture, the rotor will move a little bit farther, and so you'll see it,

01:58:08.960 --> 01:58:14.160
like, rotating really slowly around, kind of. And the point is that when you take a wave,

01:58:14.160 --> 01:58:20.080
and then you sample it at discrete points in time, if you sample too slowly, you'll basically see,

01:58:20.080 --> 01:58:23.840
like, a different wave. You'll still see a wave, but it'll just be a wave at a different frequency.

01:58:24.480 --> 01:58:29.440
And so, that's, like, the idea of aliasing is that when you sub-sample, or when you sample a

01:58:29.440 --> 01:58:34.640
wave at a lower frequency, you'll see kind of a different wave of a lower frequency.

01:58:36.080 --> 01:58:40.880
And when we look at a crystal, basically, you can think of, like, the electron in space as being

01:58:40.880 --> 01:58:46.800
this really high frequency oscillation, where the wavelength is really small, but then the actual

01:58:46.800 --> 01:58:51.840
atoms in the crystal are kind of the sites and the points in that lattice are pretty far away

01:58:51.840 --> 01:58:56.640
from each other compared to the wavelength of the electron, at least if the electron is moving fast

01:58:56.640 --> 01:59:02.160
enough. And so, what actually ends up being important is, like, what the electron looks like

01:59:02.160 --> 01:59:07.040
where it's close to the atoms. And if you think of the atoms as kind of, like, measuring, or, like,

01:59:07.040 --> 01:59:12.000
yeah, measuring what the electron looks like, if the frequency or the wavelength of that electron,

01:59:12.000 --> 01:59:18.000
if the wavelength is really small, as far as the atoms are concerned, they'll see it as being just

01:59:19.040 --> 01:59:23.280
at a lower frequency or being at a higher wavelength. And so, that's really what's happening here,

01:59:23.280 --> 01:59:28.560
where when we compare these two, when we go move forward on the x-axis, when we move from left to

01:59:28.560 --> 01:59:34.160
right, is that we're increasing the frequency or decreasing the wavelength of the electron

01:59:35.200 --> 01:59:43.440
until it gets small enough that the wavelength starts to look longer, actually, relative to the

01:59:43.440 --> 01:59:47.840
atoms. So, you could think of it as, like, I'm recording a helicopter at a constant shutter

01:59:47.840 --> 01:59:53.440
speed and the speed of the rotor speeds up and speeds up. And on my camera, I see the rotor

01:59:53.440 --> 01:59:58.320
getting faster and faster until it gets fast enough that it starts to, that it slows down. It

01:59:58.320 --> 02:00:04.560
actually looks like it's at a lower frequency. And so, in the quantum, the way to think about this

02:00:04.560 --> 02:00:09.280
in a quantum way is that the electron is a wave that's basically being measured by all the atoms,

02:00:09.280 --> 02:00:15.280
or it's kind of, its energy depends on what it looks like relative to all the atoms. And so,

02:00:15.280 --> 02:00:20.480
where that kind of speed limit comes from is that when you increase the energy of the electron enough,

02:00:20.480 --> 02:00:27.520
it, like, crosses over into that, like, aliasing, basically. And so, now, it, you know, it, well,

02:00:27.520 --> 02:00:33.040
its energy is going to end up decreasing again. That's definitely losing a lot in kind of the,

02:00:34.880 --> 02:00:39.200
it's losing a lot, but I think that's at least a start towards understanding it. And partly,

02:00:39.200 --> 02:00:44.320
because I don't understand it myself very well, but because I need to read this chapter in more

02:00:44.320 --> 02:00:49.520
detail of it, yeah. Right now, that totally makes sense. So, essentially, we had this, like,

02:00:49.520 --> 02:00:54.160
semiconductor, and you have to say, you could use, I suppose, temperature to change the,

02:00:54.960 --> 02:01:02.400
to translate the band of energy one way or another, right? And effectively, it's kind of like alignment

02:01:02.400 --> 02:01:08.960
of reference frames, that electron can, you just have to, you just have to make it possible for

02:01:08.960 --> 02:01:14.160
electron to sort of, you know, manifest in the material, so to speak, from the, from the electron

02:01:14.160 --> 02:01:21.280
field. Right. Yeah, or you could imagine as, like, what, like, what you would do if you were

02:01:21.280 --> 02:01:25.680
trying to accelerate the electrons as you would, you would apply an electric field, kind of, and

02:01:25.680 --> 02:01:30.720
so that would be, like, trying to get the electrons to move over to the, to the right in this, in this

02:01:30.720 --> 02:01:36.000
picture. But I'm trying to, specifically, not to think in classical terms, just try to get used

02:01:36.000 --> 02:01:41.600
to thinking in terms of waves. So, it's more like, I want the information transfer to some,

02:01:42.160 --> 02:01:47.040
to happen, but to do that, I have to align my sampling frequency, my reference frame,

02:01:48.080 --> 02:01:54.400
in order to let the, to be able to observe the thing it wants, so the information starts flowing.

02:01:55.280 --> 02:02:02.080
Right. Yeah. Yeah, that was a very good description. And as you were saying about

02:02:02.080 --> 02:02:06.960
moving these paraboloids, I was like, exactly, that feels like, yeah, that's, that's kind of,

02:02:06.960 --> 02:02:10.480
like, aliasing. And it's interesting that in some videos, you know, sometimes you have these funny

02:02:10.480 --> 02:02:14.640
videos of, like, a bird in front of, like, some ring camera or something, and it looks like it's

02:02:14.640 --> 02:02:20.320
just hovering in the air. The wings are perfectly synchronized with the shutter, so it looks as

02:02:20.320 --> 02:02:28.000
they're not moving. That's what there is. Yeah. Yeah, that's exactly it. And that's why they,

02:02:28.000 --> 02:02:34.000
they have, well, so to go back to this thing we were talking about, called the unit cell, or the,

02:02:34.000 --> 02:02:38.720
well, actually, in particular, the Wigner-Seitz unit cell, there's this, like, really important,

02:02:38.720 --> 02:02:42.400
this, like, maybe, like, one of the most important concepts in solid state physics is what's called

02:02:42.400 --> 02:02:48.160
the Brillouin zone, or the first Brillouin zone, it was, like, kind of a special case of it, named

02:02:48.160 --> 02:02:53.280
out this guy, Leon Brillouin, who actually also made some important contributions to the information

02:02:53.280 --> 02:02:58.640
theory. And as it's just a plug, Brillouin, he has this good book called Science and Information

02:02:58.640 --> 02:03:05.200
Theory. But the, the idea of the Brillouin zone is really all about that aliasing, that, well,

02:03:05.200 --> 02:03:09.360
first of all, we're in three dimensions here. So the frequency, or the spatial frequency,

02:03:09.360 --> 02:03:14.800
which is how many ripples the wave has when you take a step in some direction, is not just a

02:03:14.800 --> 02:03:18.640
number, but it's a vector, right? Because if I take a step in one direction, there might be a lot

02:03:18.640 --> 02:03:22.640
of ripples. But if I take a step in another direction, there might be no ripples, right? Like,

02:03:22.640 --> 02:03:27.040
if you just think of, like, waves on the beach, if I'm going perpendicular to the beach, to the

02:03:27.040 --> 02:03:32.160
beach head, I see a bunch of ripples. Whereas if I'm walking, like, parallel to the beach head,

02:03:32.160 --> 02:03:38.400
I won't cross any ripples, right? So that's why it's called a wave vector, which is both the

02:03:39.360 --> 02:03:44.800
frequency and the direction which the waves are propagating, getting in. And so we're in this

02:03:44.800 --> 02:03:49.360
three-dimensional space of all the possible wave vectors, right? That's what's called reciprocal

02:03:49.360 --> 02:03:54.160
space. A point in that space represents a wave that is, that has a particular frequency,

02:03:54.160 --> 02:03:59.280
and is traveling in a particular dimension, direction. And now, when I go out far enough

02:03:59.360 --> 02:04:03.040
to farther and farther frequency waves, eventually I get a wave that,

02:04:03.920 --> 02:04:09.120
from the crystal's perspective, looks the same because of aliasing. And so what they do is

02:04:09.120 --> 02:04:13.920
they basically say, well, it's periodic. You're not allowed to, like, really cross out of that

02:04:13.920 --> 02:04:19.120
zone. You kind of come back through the other side of it. And that zone is called the Brillouin zone,

02:04:19.120 --> 02:04:24.240
or the first Brillouin zone, in what they call cave space, sort of space of all wave vectors.

02:04:24.880 --> 02:04:30.160
And that's like, it's probably the most, like, fundamental thing that characterizes a crystal,

02:04:30.160 --> 02:04:35.920
is what it's like Brillouin zone looks like, or, you know, which describes the geometry of the

02:04:35.920 --> 02:04:40.960
lattice, basically, in terms of the waves. So yeah, that's how I think you can kind of think about

02:04:40.960 --> 02:04:46.320
the, this, like, aliasing connection in a crystal and what the Brillouin zone is.

02:04:46.880 --> 02:04:49.760
Right. That's really interesting.

02:04:51.600 --> 02:04:55.760
Yeah. Sorry. Go ahead.

02:04:57.520 --> 02:05:02.000
Yeah, actually, yeah, I'm not sure, but I think, like, the picture on the cover of the book,

02:05:02.000 --> 02:05:06.720
it's probably either, like, a Fermi surface or a Brillouin zone. I'm not actually sure. It's

02:05:06.720 --> 02:05:09.440
probably one or the other, but I don't really know, honestly. But yeah.

02:05:16.640 --> 02:05:24.640
But yeah, go ahead, Christophe, are you going to say something?

02:05:25.680 --> 02:05:29.440
I don't know that your exposition just still made me think about this,

02:05:29.440 --> 02:05:32.960
that this fact that you always have this sort of situation of being,

02:05:34.480 --> 02:05:38.000
you know, unlimited observer, observing some phenomenon that has more degrees of freedom

02:05:38.000 --> 02:05:44.640
than you have. So in this case, the fact that you just simply have to conflate

02:05:46.800 --> 02:05:53.760
information you get because of this aliasing, because of these very, very, very high frequency

02:05:53.760 --> 02:05:57.040
waves that, you know, you just can't observe the fact that they're so high frequency,

02:05:57.040 --> 02:06:00.080
do you just have to conflate it with whatever you can measure?

02:06:01.360 --> 02:06:06.240
Right. Yeah. Yeah, and actually, there's something they call, like, a crystal momentum,

02:06:06.240 --> 02:06:11.360
which is like, so the electron, of course, has some, like, physical momentum, right,

02:06:11.360 --> 02:06:15.600
which is either, you could think of it as, like, h times k, its wave vector,

02:06:15.600 --> 02:06:20.400
or as, like, m times v, its mass times velocity, but it also has a crystal momentum,

02:06:20.400 --> 02:06:25.840
which is that momentum basically aliased to the crystal. And so, yeah, it really is like that,

02:06:25.840 --> 02:06:31.280
like, that the world it's living in, which is, like, discreet, is basically determining, you know,

02:06:32.240 --> 02:06:36.240
to what, like, resolution you can view its properties, kind of.

02:06:36.480 --> 02:06:44.560
Yeah. Yeah. And the crystal momentum ends up being, like, the kind of conserved quantity

02:06:44.560 --> 02:06:49.200
in, within the crystal. So it's almost like this, it's almost like a bad simulation of

02:06:49.200 --> 02:06:52.320
reality. How do you think of, like, what's going on in the crystal is, like, this,

02:06:52.320 --> 02:06:57.840
this kind of flawed simulation, where it can't really understand momentum, like, above a certain

02:06:57.840 --> 02:07:01.760
point. And so it just aliases them back to below that kind of, you know.

02:07:01.760 --> 02:07:07.760
Well, you know, there's this, one of the seven hermetic principles from hermetic philosophy,

02:07:07.760 --> 02:07:13.360
it's basically says, as above so below, so below as above, and turns McKenna very nicely restated

02:07:13.360 --> 02:07:21.920
that nature is self-similar across scale. So in some sense, the space within a crystal that

02:07:21.920 --> 02:07:29.040
permits the electron field to invade that structure, right, will reflect the structure

02:07:29.040 --> 02:07:35.200
of the field up to whatever can be reflected in the structure, right? Like, it's kind of,

02:07:35.200 --> 02:07:42.000
like, almost logical that you can capture whatever you can capture. And as long as soon as, as soon

02:07:42.000 --> 02:07:52.640
as the conditions for the flow of the electron field into the into the crystal are satisfied,

02:07:52.640 --> 02:07:56.880
then it will just naturally tend to expand into wherever it can it can go.

02:07:57.840 --> 02:08:03.840
Yeah. Yeah, yeah, no, it definitely, yeah, definitely, I think that's a good way of thinking

02:08:03.840 --> 02:08:09.280
about it. It's, it's really, it's almost like a, it's almost like a different universe when you're,

02:08:09.280 --> 02:08:13.840
when you're inside of a crystal and you're the size of the electron and the crystal is,

02:08:13.840 --> 02:08:20.000
for your purposes, it's basically infinitely large. And it has its own kind of laws of physics,

02:08:20.000 --> 02:08:23.760
like that ends up being, I think, the right way to think about it. And of course, you can think

02:08:23.760 --> 02:08:27.760
of it everything in terms of our ordinary laws of physics, right? And you can just apply Schrodinger's

02:08:27.760 --> 02:08:34.400
equation and everything. But the way to, you know, the way that the theory really develops in that

02:08:34.400 --> 02:08:38.800
we predict all these properties is like thinking of its own little universe that has its own laws

02:08:38.800 --> 02:08:43.840
kind of based on this, you know, based on this structure where space is kind of discretized

02:08:43.840 --> 02:08:49.440
or at least like periodic in a way. Yeah. And you know, to go back to one of our previous

02:08:49.440 --> 02:08:54.000
conversations when they said about how Maxwell used to think about the world and he had this,

02:08:54.000 --> 02:08:59.120
he had this model of the, of the world and the model of what the function of a scientist is,

02:08:59.120 --> 02:09:04.560
is to basically use the intuition from the physical, from the mechanical, from the familiar,

02:09:04.560 --> 02:09:12.000
from the scale that we operate on to construct a model of what's happening on other scales by,

02:09:12.000 --> 02:09:17.440
and by kind of analogizing. And I think this is what we've been doing in the book so far.

02:09:17.440 --> 02:09:22.400
A lot of this stuff was like, well, the electrons are kind of like gas, but not really,

02:09:22.400 --> 02:09:27.360
but let's just apply the same mathematics and see what shakes out and we got some approximation of

02:09:27.360 --> 02:09:32.400
what's happening in the material and so on and so forth. And at some point you're starting to relax

02:09:32.400 --> 02:09:38.720
the assumptions of the, that are familiar, the localization in space and time and so on and so

02:09:38.720 --> 02:09:44.320
forth. And you get this, and you get these more interesting models. But the parallel that there

02:09:44.320 --> 02:09:49.600
was always some parallel to be made with the phenomena that are familiar to us at our scale,

02:09:49.600 --> 02:09:55.840
because at all scales, nature, nature, nature is self-similar. It doesn't mean it's the same,

02:09:55.840 --> 02:10:02.400
it just means that there are aspects that, you know, can be captured with at a higher level,

02:10:03.040 --> 02:10:07.120
that it can be captured at a lower level and vice versa. And Hermetics would say something

02:10:07.120 --> 02:10:13.440
cryptic that like, you know, by comprehending the monad, he understands the archangel that you can

02:10:13.520 --> 02:10:18.080
infer the structure of the heavens from what's happening on earth.

02:10:19.760 --> 02:10:26.000
Right. Yeah. And as you were saying, like about how, I think this is like a good kind of like,

02:10:26.000 --> 02:10:30.960
yeah, theme of the book is like different ways of approximating reality by pretending it's

02:10:30.960 --> 02:10:35.440
something that's like relatively easier for us to reason about, right? And so we start off by

02:10:35.440 --> 02:10:40.240
imagining that it's just a bunch of balls bouncing around in this Pashinko machine or whatever.

02:10:40.960 --> 02:10:47.040
And then you kind of expect like, yeah, as we go down to the quantum level and incorporate more,

02:10:47.040 --> 02:10:51.680
more physics, like things are kind of getting more realistic in a way they are, like in a way

02:10:51.680 --> 02:10:56.080
it's getting more realistic and we can get better predictions. But in another way, it's actually,

02:10:56.080 --> 02:11:01.280
we end up like ignoring more and more things actually, like as we include more quantum physics,

02:11:01.280 --> 02:11:05.440
we realized, oh, well, there's also all these like, not only are the electrons interacting

02:11:05.440 --> 02:11:09.520
with each other, but they can also be entangled with each other or with the nuclear things like

02:11:09.520 --> 02:11:14.320
that, but we're gonna, we can throw that out the window basically for various reasons. And so as

02:11:14.320 --> 02:11:19.600
the model gets more complex, it also becomes more reductive actually, which, you know, so if we

02:11:19.600 --> 02:11:26.160
started off with a, with a spherical cow, we ended up with, there's a guy I talked to on here who,

02:11:26.160 --> 02:11:30.560
who said that he somehow mixed it up and said that we, that physics, we like to make things

02:11:30.560 --> 02:11:35.600
into flat cows, which is maybe not a bad way to think. We started off with a spherical cow and

02:11:35.600 --> 02:11:39.600
we end up with a flat cow or something that's even somehow even more reductive basically.

02:11:40.800 --> 02:11:46.080
But it is interesting that we end up with better predictions, but there's still like extremely

02:11:46.080 --> 02:11:51.440
like simplistic ways to look at the world because what we really get out of our, you know, theoretical

02:11:51.440 --> 02:11:54.800
advancements is we realize there's all this complexity and all these other effects that

02:11:54.800 --> 02:12:00.880
can happen. And then the kind of game is to figure out what, you know, we can ignore and whether we

02:12:00.880 --> 02:12:07.280
can kind of ignore more and more different things, I think. Yeah. I guess in some sense, you can,

02:12:07.280 --> 02:12:13.200
you can start ignoring things like entanglement and so on, because you're looking at this from a

02:12:13.200 --> 02:12:21.520
very statistical perspective in a way that like you're, we're taking very large samples of,

02:12:24.080 --> 02:12:29.920
you know, of the system, like in the temporal scale, compared to the interactions between

02:12:29.920 --> 02:12:35.280
individual electrons with electrons and electrons with atoms. By the time we care about any effect

02:12:35.280 --> 02:12:43.040
of that, there has been so many that any individual entanglements and non-New Yorker relations and

02:12:43.040 --> 02:12:48.160
all of that just kind of like have been smoothed out until, until we find effects where we care

02:12:48.160 --> 02:12:52.560
and we're going to have to go back and be like, okay, now we can measure, now we can, now we

02:12:52.560 --> 02:12:58.720
actually see the difference. Yeah. Yeah, definitely. I mean, and especially because like when in terms

02:12:58.720 --> 02:13:04.320
of the classical way of thinking, like whenever you want to incorporate some new effect, kind of

02:13:04.320 --> 02:13:09.760
the first tool in the toolbox is to like just use some Taylor expansion to say like, well, yeah,

02:13:09.760 --> 02:13:13.760
what's the first order dependence on this? And like, what's the second order dependence?

02:13:14.880 --> 02:13:19.200
And so the more effects you try to include, you basically end up with some kind of crazy

02:13:19.200 --> 02:13:25.280
Taylor expansion in a bunch of different variables, which ends up being like not a very useful model

02:13:25.280 --> 02:13:29.440
and not very wieldy, and it doesn't really help you understand the thing intuitively too well.

02:13:30.000 --> 02:13:35.120
But yeah, there's something I'm really curious about is, so something kind of an idea I've been

02:13:35.120 --> 02:13:39.520
working on and thinking about a little bit is like whether we can, because we've talked about this

02:13:39.520 --> 02:13:44.080
before actually how like maybe the like neural networks are going to be the Taylor expansion

02:13:44.080 --> 02:13:50.000
of the 21st century in that not only we'll use them for just extrapolation, but they'll also

02:13:50.480 --> 02:13:56.080
become kind of the basis of like the math of theoretical physical models basically of things.

02:13:57.120 --> 02:14:02.000
And I've kind of been thinking about like, you know, is there a way to leverage like thermodynamics

02:14:02.000 --> 02:14:08.160
to figure out what's the right function basically to fit with neural networks to get a good

02:14:08.160 --> 02:14:17.040
understanding of materials basically. And but yeah, basically using kind of neural networks as a

02:14:18.000 --> 02:14:23.360
on zots for thermodynamic functions, like potential thermodynamic potentials like free

02:14:23.360 --> 02:14:27.840
energies and partition functions and things like that to model materials and semiconductors and

02:14:27.840 --> 02:14:33.040
stuff like that. Yeah, I have a feeling that there definitely is there is a there are some

02:14:33.040 --> 02:14:38.080
really interesting theoretical results that that that that suggests that that might be possible.

02:14:38.080 --> 02:14:42.400
Are you familiar with the technique called Cindy sparse identification of nonlinear dynamics?

02:14:43.280 --> 02:14:46.400
No, actually, yeah, I know I haven't heard of that. So the idea is really simple.

02:14:47.520 --> 02:14:51.360
You know, there's a great paper about Cindy Ote and coders and just trying to reproduce the

02:14:51.360 --> 02:14:57.840
results from right now. Actually, you take something like a high dimensional representation of a

02:14:57.840 --> 02:15:03.600
system. So for instance, a video of a pendulum or just generated, you know, animation of a

02:15:03.600 --> 02:15:10.400
damped pendulum. And what you want is to produce the equations of motion. So there are two things

02:15:10.400 --> 02:15:17.680
that need to happen. One is essentially coordinate transformation that will allow you to discover

02:15:17.680 --> 02:15:22.960
a low dimensional coordinate system that describes the motion of a pendulum, in this case, a single

02:15:22.960 --> 02:15:29.840
variable coordinate system, right? And the nice thing is that when you're investigating, you

02:15:29.840 --> 02:15:33.440
already know the answer. So like, you can, you know, the answers, you know, the governing equations,

02:15:33.440 --> 02:15:37.600
you can generate the data, you can you can simulate it to your heart content, and then you

02:15:37.600 --> 02:15:42.240
can start playing with neural networks. It's a very fun thing to play with. So you squeeze it

02:15:42.240 --> 02:15:46.560
from auto encoder into some kind of low dimensional space. And you say like, okay, I'm going to have

02:15:46.560 --> 02:15:54.400
this low dimensional representation. And then you can you have this dictionary of candidate

02:15:54.400 --> 02:16:01.040
functions from which you can you can construct the governing equation. And what you're trying to do

02:16:01.040 --> 02:16:09.680
is a is a kind of a linear regression with a lost term that encourages sparsity. So you want you

02:16:09.680 --> 02:16:14.880
essentially trying to say to the neural network, please find me a coordinate transformation of

02:16:14.880 --> 02:16:21.040
the system from high dimensional, from this high dimensional space of my observations of data

02:16:21.040 --> 02:16:25.840
into something that's low dimensional. That's actually I'm able to doing this regression

02:16:25.840 --> 02:16:33.840
technique that will give me an equation in that in the low dimensional, you know, coordinates.

02:16:34.720 --> 02:16:44.640
That's also sparse. And it's, it's a bit fragile. But it's, it can be made to work. And people

02:16:44.640 --> 02:16:51.200
actually apply that to reinforcement learning as well. So you have an reinforcement learning agent

02:16:51.200 --> 02:16:58.160
that interacts with, you know, the costly simulation of some kind of physical system site,

02:16:58.160 --> 02:17:02.480
and then you construct a Cindy model, and it doesn't have to be perfect, but you have something.

02:17:02.480 --> 02:17:07.200
And then you learn then the reinforcement learning for a while can learn, you know,

02:17:07.200 --> 02:17:12.240
against this reduced model, that's really cheap to compute because you have the equation. So you can

02:17:12.240 --> 02:17:18.160
just, you can just sort of, you know, guide the guide the learning in a certain direction,

02:17:18.160 --> 02:17:23.600
if it is not perfect. And then you do the rollout of the new neural network into the

02:17:24.400 --> 02:17:29.760
full environment, and collect more data, and so on, and you continue. And that can actually,

02:17:29.760 --> 02:17:37.760
that can dramatically improve sample efficiency when modeling physical systems. So, you know,

02:17:37.760 --> 02:17:47.040
I think, I think as time goes on, we will effectively get an entire lingo of how to

02:17:47.760 --> 02:17:54.560
essentially think about this, almost as if like, you know, how many degrees of,

02:17:56.160 --> 02:18:01.040
I feel that it's something related to tensor decomposition, tensor network decomposition

02:18:01.040 --> 02:18:11.360
and the area law, that, you know, for certain situations, you can sort of know that, you know,

02:18:11.360 --> 02:18:18.480
the nonlinear correlations are not that important to the thing that you're trying to model in the

02:18:18.480 --> 02:18:23.200
state that you're trying to model because it's kind of the ground state that you really care about.

02:18:23.200 --> 02:18:27.520
So the area law kind of starts to apply and you only care about what's observable on the

02:18:27.520 --> 02:18:34.240
boundary between the system and the environment. And if you, if we could figure out how to sort

02:18:34.240 --> 02:18:40.000
of dynamically adjust the neural network somehow to figure out what is the optimal size of that

02:18:40.000 --> 02:18:44.960
boundary, right? That's going to be the kind of vocabulary that we're going to have. You're

02:18:44.960 --> 02:18:48.640
going to have these systems that are just basically your modeling entangled system,

02:18:48.640 --> 02:18:54.960
that's the function of a neural network to simply model nonlinear correlations in a kind of

02:18:54.960 --> 02:19:01.920
an entangled system. And then your, the important part is going to be the specification of the

02:19:01.920 --> 02:19:08.240
bandwidth of the boundary between the components of the system. So you can think of the one-dimensional

02:19:08.240 --> 02:19:12.160
Ising model as this very specific structure. And that's why that's precisely why you can

02:19:12.160 --> 02:19:16.880
decompose it because the interactions only happen at this very well-defined boundary,

02:19:16.880 --> 02:19:22.960
something along those lines. Interesting. Yeah. And while I like the analogy of the Ising model,

02:19:22.960 --> 02:19:27.680
for example, because like, yeah, Ising models are like one of the kind of triumphs of

02:19:28.400 --> 02:19:33.120
statistical physics was like deriving partition functions for Ising models and like one and two

02:19:33.120 --> 02:19:37.840
dimensions and stuff like that. But then like that's like about as kind of far as wet because

02:19:37.920 --> 02:19:42.240
anything that's, and that's like already a pretty incredibly simple, you know, model. But

02:19:42.240 --> 02:19:46.640
when you go to things that are more complicated, it's just analytically pretty much impossible to

02:19:46.640 --> 02:19:52.080
do in a closed form. And it's just kind of why I think like, you know, the behavior ultimately

02:19:52.080 --> 02:19:57.360
can't be that complicated. It's just our way of describing it that is not a good fit. Like it's

02:19:57.360 --> 02:20:01.600
just our, when we try to write out an equations and the closed forms that we're familiar with,

02:20:01.600 --> 02:20:06.480
that's not a good fit. So I think ultimately a partition function won't be something you try to

02:20:06.560 --> 02:20:11.520
derive, but something you download, you know, from Hugginface or whatever. And then off you go,

02:20:12.560 --> 02:20:17.840
you know, modeling the thermodynamics of your system. And to do this now, we basically do all

02:20:17.840 --> 02:20:22.480
these really expensive Monte Carlo simulations where we do, you know, millions of simulated

02:20:22.480 --> 02:20:28.480
trajectories of a system, because we don't have a closed form for its, you know, its statistical

02:20:28.480 --> 02:20:34.560
the functions that describe as statistics. And I just think that like, these functions can be

02:20:34.560 --> 02:20:40.080
learned. And they're, you know, they're not like input output for like a self driving car,

02:20:40.080 --> 02:20:43.920
but they are, they're, they're still functions that, you know, describe the statistics of these

02:20:43.920 --> 02:20:50.320
many body systems. So, but here's what the right data is, you know, here's a kicker. There's a

02:20:50.320 --> 02:20:56.800
paper that I think is going to be, to turn out to be a lot more important than so far it has been,

02:20:56.800 --> 02:21:02.320
it's titled, your classifier is secretly an energy based model, and you should treat it as such.

02:21:02.320 --> 02:21:11.760
Let me, one second. So the gist of the paper is basically that if you take a standard classifier

02:21:11.760 --> 02:21:18.560
trained on a cross entropy loss, it's actually hiding a full generative model. So let me just

02:21:18.560 --> 02:21:23.360
read you the abstract, this is really interesting. We propose to reinterpret a standard discriminative

02:21:23.360 --> 02:21:29.840
classifier p of y given x as an energy based model for the joint distribution p of x and y.

02:21:29.920 --> 02:21:33.920
In this setting, the standard class probabilities can be easily computed as well,

02:21:33.920 --> 02:21:40.800
unnormalized values p of x and p of x given y. So basically, what it, what it, what it is saying

02:21:40.800 --> 02:21:48.960
is that even though the partition function is generally intractable, by doing classification,

02:21:48.960 --> 02:21:51.520
you're getting effectively a partition function for free.

02:21:52.480 --> 02:21:57.760
Right. Interesting. Yeah, probably that's interesting. You can somehow sample p of x

02:21:57.840 --> 02:22:05.280
or compute p of x from a classifier that is supposed to give you p of x given y or p of y

02:22:05.280 --> 02:22:11.200
given x, I guess. It's wild. I'll just post the link to the paper, but like it's, I think it's,

02:22:11.200 --> 02:22:18.400
and they also have a follow up work. It's called entitled oops, I took a gradient, and they show

02:22:18.400 --> 02:22:24.560
how there was a very, there was a much better way to sample from that, that they have a very,

02:22:24.560 --> 02:22:30.240
very nice improved sampling, sampling algorithm. So yeah, I totally agree with you that like these,

02:22:30.240 --> 02:22:35.680
these neural networks will be these partition functions that you sort of, they will be,

02:22:35.680 --> 02:22:42.480
they are these partition functions. A classifier is a partition function and a general model.

02:22:42.480 --> 02:22:46.880
So you can use it, you can use it both ways. You can, you can generate from it and you can

02:22:46.880 --> 02:22:51.280
actually use it to solve your problems. So I think, I think there's going to be a new,

02:22:51.280 --> 02:22:56.240
new vocabulary, that's the top of that vocabulary, new kind of physics will emerge.

02:22:56.880 --> 02:23:02.080
Oh yeah, oh yeah, definitely. And I mean, I think like one of the things that it's been kind of,

02:23:02.080 --> 02:23:07.520
we've seen recently is like, you know, AI has done really good at these kind of like trial and error

02:23:08.080 --> 02:23:13.040
things where it has really good guesses basically, like alpha geometry, it can guess a proof that

02:23:13.040 --> 02:23:18.400
can then be checked by some formal proof system. And I think like these just in check tasks,

02:23:18.480 --> 02:23:23.600
where the checking is really easy are like the key to AI, I'm not going to use the term AGI,

02:23:23.600 --> 02:23:28.800
but things that we would all agree have surpassed like human capability, like AlphaGo and in

02:23:28.800 --> 02:23:33.920
chess and whatever that we're like, because it can be checked, you know, it can, it can quickly

02:23:33.920 --> 02:23:39.200
learn to play better than a human. And I think it's going to be similar with like material science

02:23:39.200 --> 02:23:44.240
basically that will be because there's so much effort that goes into trying to like guess what

02:23:44.240 --> 02:23:48.960
good materials will be. And then they run, you know, density functional theory, DFT or whatever.

02:23:48.960 --> 02:23:53.040
And they say, Oh, well, it didn't didn't work out so well after all. But this seems like a

02:23:53.040 --> 02:23:58.320
perfect application for, you know, basically learning to, you know, learning to produce

02:23:58.320 --> 02:24:02.240
materials that have the properties you want, basically. Yeah, but you know, there's a project

02:24:02.240 --> 02:24:05.920
that I'm thinking I've been thinking about for a while. And I don't know if I should mention it

02:24:05.920 --> 02:24:10.320
here, because it's good. If this stuff actually works, it's going to have some funny consequences

02:24:10.320 --> 02:24:15.760
for the world. But maybe like, you know, to help with it, like, imagine that you what you're guessing

02:24:15.760 --> 02:24:26.480
is the is is the and nonce of the Bitcoin block. So train train train a neural network to basically

02:24:26.480 --> 02:24:32.480
use use neural acceleration to basically break Bitcoin, and be able to get to get every single

02:24:32.480 --> 02:24:38.880
block. There's like a billion dollars to be made right there. Right. I see. Yeah, that's although

02:24:38.880 --> 02:24:44.400
you made Bitcoin as a result. Yeah, yeah, I looked into some papers at one point, not not like

02:24:44.400 --> 02:24:48.000
terribly similar, but I guess a little bit related and like trying to attack encryption

02:24:48.000 --> 02:24:52.640
with neural networks was like a, like people tried training a neural network to predict

02:24:53.440 --> 02:24:59.440
like PRNGs basically, like an attack on PRNGs by trying to predict their outputs from a portion

02:24:59.440 --> 02:25:05.360
of their outputs. I don't think it did terribly well. But yeah, I mean, I think that the function

02:25:05.360 --> 02:25:12.640
is just too like, you know, discontinuous. Or I mean, maybe not. Like, it's just too complex to

02:25:12.640 --> 02:25:18.160
describe the function in the parameterization of the neural network, basically, like you who need

02:25:18.160 --> 02:25:24.080
to, you would need so many, like the complexity is probably worse than other like known attacks

02:25:24.080 --> 02:25:29.280
that are already that people already know how to do will be my guess. But I don't know, maybe

02:25:29.280 --> 02:25:33.520
there's like, to me will be surprising if there turned out to be some structure that it could

02:25:33.520 --> 02:25:38.320
understand. But, you know, maybe there is, I don't know, but yeah, my guess is that hash functions

02:25:38.320 --> 02:25:44.080
are more primitive. So, so there is a more possibility for that. And also the, you know,

02:25:44.080 --> 02:25:48.080
you could do the initial what you could try is do they have a neural network to have the initial

02:25:48.080 --> 02:25:52.640
gas, and then just simply iterate from there. Just assume that it's that the neural network

02:25:52.640 --> 02:25:57.440
might be guessing somewhere in the vicinity, which is a little bit different from, which is,

02:25:57.440 --> 02:26:01.840
I think it's a smaller space than encryption, because there's this non, well, it's a big number.

02:26:02.480 --> 02:26:07.040
I think it's a, it's more constrained than the general encryption problem.

02:26:07.680 --> 02:26:12.960
I see. Yeah. Yeah, I mean, you know, it will be, I mean, yeah, if it worked, like it would prove,

02:26:12.960 --> 02:26:18.080
you know, it would probably be a breakthrough in, in just computer science in general, you know,

02:26:18.080 --> 02:26:22.480
if you could do something with better complexity with somewhere in the algorithm. I think what

02:26:22.480 --> 02:26:26.800
it will probably be really good at is finding like implementation errors, right? Because a lot of

02:26:26.800 --> 02:26:31.120
these like, you know, how do you know if there's an implementation error in your crypto, you know,

02:26:31.200 --> 02:26:36.880
not until something goes wrong, but because people can't really find the patterns too easily.

02:26:37.760 --> 02:26:41.920
But yeah, maybe, you know, you probably do pretty well at finding patterns that are there just

02:26:41.920 --> 02:26:47.280
because of some implementation bug or something like that. Yeah, you know, so people did apply

02:26:47.280 --> 02:26:53.600
some kind of lattice methods to like, if you have bugs in your implementation, like for instance,

02:26:53.680 --> 02:27:02.240
if you reuse nonce, then you, the number you're supposed to only use once, then it's actually

02:27:02.240 --> 02:27:09.040
trivial to recover your private keys. And there are, in the sort of like a dark forest, you know,

02:27:09.040 --> 02:27:15.280
tradition, there are bots who are looking for it. So if they, if they, if they ever find it,

02:27:15.280 --> 02:27:22.560
your crypto is going to be instantly, instantly gone. Yeah. So there are people who are, who are

02:27:22.560 --> 02:27:26.640
working on a lot of these sort of techniques, and they're already scanning the network for

02:27:26.640 --> 02:27:33.760
possibility of this kind of stuff happening. Right. Yeah. Pretty amusing, in a way. It's kind of like

02:27:33.760 --> 02:27:40.480
that. Yeah. Yeah. All right. Well, yeah, I think I'm gonna, gonna go take a break for a bit,

02:27:40.480 --> 02:27:44.560
have a little bit of work I was gonna finish up. But yeah, I think this was, this was fun space,

02:27:44.560 --> 02:27:49.680
this went well, we went through, you know, most of the material. So, and had a lot of interesting

02:27:49.760 --> 02:27:55.840
questions and, and observations. So thank you. Your exposition is amazing. Thank you. Yeah.

02:27:56.560 --> 02:28:01.680
Thank you, Max. Appreciate it. Thank you. Yeah, thanks everyone for coming. We, if everything goes

02:28:01.680 --> 02:28:07.440
according to plan, we'll be having another one next week, same time. So yeah, please come out.

02:28:07.440 --> 02:28:13.520
And yeah, thanks again, everyone. So see you guys. Bye bye.

02:28:19.680 --> 02:28:21.060
you

